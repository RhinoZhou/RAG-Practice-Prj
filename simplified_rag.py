#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åŒ»ç–—çŸ¥è¯†é—®ç­”ç³»ç»Ÿ (Medi-RAG)

æœ¬ç³»ç»Ÿæ˜¯ä¸€ä¸ªåŸºäºæ£€ç´¢å¢å¼ºç”Ÿæˆ(RAG)æŠ€æœ¯çš„åŒ»ç–—çŸ¥è¯†é—®ç­”ç³»ç»Ÿï¼Œæ”¯æŒå¤šçŸ¥è¯†åº“ç®¡ç†ã€å¤šè½®å¯¹è¯ã€
æ™®é€šè¯­ä¹‰æ£€ç´¢å’Œé«˜çº§å¤šè·³æ¨ç†åŠŸèƒ½ã€‚
"""

import os
import sys
import time
import logging
import importlib.util
from datetime import datetime

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler("medi_rag.log"),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# ç›´æ¥å¯¼å…¥æ‰€æœ‰å¿…è¦çš„åº“
try:
    print(f"[{time.strftime('%H:%M:%S')}] å¼€å§‹å¯¼å…¥æ‰€æœ‰å¿…è¦çš„åº“...")
    start_time = time.time()
    
    # åŸºç¡€åº“
    import torch
    print(f"[{time.strftime('%H:%M:%S')}] âœ“ å¯¼å…¥ torch æˆåŠŸ")
    
    import faiss
    print(f"[{time.strftime('%H:%M:%S')}] âœ“ å¯¼å…¥ faiss æˆåŠŸ")
    
    import numpy as np
    print(f"[{time.strftime('%H:%M:%S')}] âœ“ å¯¼å…¥ numpy æˆåŠŸ")
    
    import pandas as pd
    print(f"[{time.strftime('%H:%M:%S')}] âœ“ å¯¼å…¥ pandas æˆåŠŸ")
    
    import nltk
    print(f"[{time.strftime('%H:%M:%S')}] âœ“ å¯¼å…¥ nltk æˆåŠŸ")
    
    import tqdm
    print(f"[{time.strftime('%H:%M:%S')}] âœ“ å¯¼å…¥ tqdm æˆåŠŸ")
    
    import PyPDF2
    print(f"[{time.strftime('%H:%M:%S')}] âœ“ å¯¼å…¥ PyPDF2 æˆåŠŸ")
    
    import docx
    print(f"[{time.strftime('%H:%M:%S')}] âœ“ å¯¼å…¥ docx æˆåŠŸ")
    
    # å¯¼å…¥llama_indexç›¸å…³åº“
    print(f"[{time.strftime('%H:%M:%S')}] å¼€å§‹å¯¼å…¥ llama_index ç›¸å…³åº“...")
    from llama_index.core.node_parser import SentenceSplitter
    print(f"[{time.strftime('%H:%M:%S')}] âœ“ å¯¼å…¥ SentenceSplitter æˆåŠŸ")
    
    from llama_index.core import VectorStoreIndex, StorageContext
    print(f"[{time.strftime('%H:%M:%S')}] âœ“ å¯¼å…¥ VectorStoreIndex å’Œ StorageContext æˆåŠŸ")
    
    from llama_index.core import load_index_from_storage
    print(f"[{time.strftime('%H:%M:%S')}] âœ“ å¯¼å…¥ load_index_from_storage æˆåŠŸ")
    
    from llama_index.vector_stores.faiss import FaissVectorStore
    print(f"[{time.strftime('%H:%M:%S')}] âœ“ å¯¼å…¥ FaissVectorStore æˆåŠŸ")
    
    # å…¶ä»–åº“
    print(f"[{time.strftime('%H:%M:%S')}] å¼€å§‹å¯¼å…¥å…¶ä»–åº“...")
    from langchain.llms import OpenAI
    print(f"[{time.strftime('%H:%M:%S')}] âœ“ å¯¼å…¥ langchain.llms.OpenAI æˆåŠŸ")
    
    from transformers import AutoTokenizer, AutoModel
    print(f"[{time.strftime('%H:%M:%S')}] âœ“ å¯¼å…¥ transformers.AutoTokenizer å’Œ AutoModel æˆåŠŸ")
    
    from sentence_transformers import SentenceTransformer
    print(f"[{time.strftime('%H:%M:%S')}] âœ“ å¯¼å…¥ sentence_transformers.SentenceTransformer æˆåŠŸ")
    
    import gradio as gr
    print(f"[{time.strftime('%H:%M:%S')}] âœ“ å¯¼å…¥ gradio æˆåŠŸ")
    
    end_time = time.time()
    
    print(f"[{time.strftime('%H:%M:%S')}] âœ“ æ‰€æœ‰å¿…è¦çš„åº“å¯¼å…¥æˆåŠŸï¼Œè€—æ—¶: {end_time - start_time:.2f} ç§’")
    print(f"[{time.strftime('%H:%M:%S')}] - PyTorchç‰ˆæœ¬: {torch.__version__}")
    print(f"[{time.strftime('%H:%M:%S')}] - FAISSç‰ˆæœ¬: {faiss.__version__}")
    print(f"[{time.strftime('%H:%M:%S')}] - NumPyç‰ˆæœ¬: {np.__version__}")
    print(f"[{time.strftime('%H:%M:%S')}] - Gradioç‰ˆæœ¬: {gr.__version__}")
    
except Exception as e:
    print(f"[{time.strftime('%H:%M:%S')}] âœ— å¯¼å…¥åº“å¤±è´¥: {type(e).__name__}: {e}")
    import traceback
    traceback.print_exc()
    sys.exit(1)

# è¯»å–é…ç½®æ–‡ä»¶
class AppConfig:
    """åº”ç”¨é…ç½®ç±»"""
    def __init__(self):
        self.EMBEDDING_MODEL = "sentence-transformers/all-MiniLM-L6-v2"
        self.LLM_MODEL = "gpt-3.5-turbo"
        self.CHUNK_SIZE = 512
        self.CHUNK_OVERLAP = 128
        self.KNOWLEDGE_BASES_DIR = "knowledge_bases"
        self.VECTOR_STORES_DIR = "vector_stores"
        
        # åˆ›å»ºå¿…è¦çš„ç›®å½•
        os.makedirs(self.KNOWLEDGE_BASES_DIR, exist_ok=True)
        os.makedirs(self.VECTOR_STORES_DIR, exist_ok=True)

# åˆå§‹åŒ–åº”ç”¨é…ç½®
app_config = AppConfig()

# çŸ¥è¯†åº“ç®¡ç†å‡½æ•°
def get_knowledge_bases():
    """è·å–æ‰€æœ‰çŸ¥è¯†åº“åç§°"""
    try:
        return [d for d in os.listdir(app_config.KNOWLEDGE_BASES_DIR) 
                if os.path.isdir(os.path.join(app_config.KNOWLEDGE_BASES_DIR, d))]
    except Exception as e:
        print(f"è·å–çŸ¥è¯†åº“åˆ—è¡¨å¤±è´¥: {e}")
        return []

def create_knowledge_base(kb_name):
    """åˆ›å»ºçŸ¥è¯†åº“"""
    if not kb_name:
        return "çŸ¥è¯†åº“åç§°ä¸èƒ½ä¸ºç©º"
    
    kb_path = os.path.join(app_config.KNOWLEDGE_BASES_DIR, kb_name)
    if os.path.exists(kb_path):
        return "çŸ¥è¯†åº“å·²å­˜åœ¨"
    
    try:
        os.makedirs(kb_path)
        return f"çŸ¥è¯†åº“ '{kb_name}' åˆ›å»ºæˆåŠŸ"
    except Exception as e:
        return f"åˆ›å»ºçŸ¥è¯†åº“å¤±è´¥: {e}"

def delete_knowledge_base(kb_name):
    """åˆ é™¤çŸ¥è¯†åº“"""
    if not kb_name:
        return "è¯·é€‰æ‹©è¦åˆ é™¤çš„çŸ¥è¯†åº“"
    
    import shutil
    kb_path = os.path.join(app_config.KNOWLEDGE_BASES_DIR, kb_name)
    vs_path = os.path.join(app_config.VECTOR_STORES_DIR, kb_name)
    
    try:
        if os.path.exists(kb_path):
            shutil.rmtree(kb_path)
        if os.path.exists(vs_path):
            shutil.rmtree(vs_path)
        return f"çŸ¥è¯†åº“ '{kb_name}' åˆ é™¤æˆåŠŸ"
    except Exception as e:
        return f"åˆ é™¤çŸ¥è¯†åº“å¤±è´¥: {e}"

# æ–‡æ¡£å¤„ç†å‡½æ•°
def process_uploaded_files(kb_name, files):
    """å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶"""
    if not kb_name:
        return "è¯·é€‰æ‹©çŸ¥è¯†åº“"
    
    if not files:
        return "è¯·é€‰æ‹©æ–‡ä»¶ä¸Šä¼ "
    
    kb_path = os.path.join(app_config.KNOWLEDGE_BASES_DIR, kb_name)
    
    try:
        for file in files:
            file_path = os.path.join(kb_path, file.name)
            with open(file_path, "wb") as f:
                f.write(file.read())
        return f"æˆåŠŸä¸Šä¼  {len(files)} ä¸ªæ–‡ä»¶åˆ°çŸ¥è¯†åº“ '{kb_name}'"
    except Exception as e:
        return f"æ–‡ä»¶ä¸Šä¼ å¤±è´¥: {e}"

# ç´¢å¼•æ„å»ºå‡½æ•°
def build_index(kb_name):
    """æ„å»ºçŸ¥è¯†åº“ç´¢å¼•"""
    if not kb_name:
        return "è¯·é€‰æ‹©çŸ¥è¯†åº“"
    
    kb_path = os.path.join(app_config.KNOWLEDGE_BASES_DIR, kb_name)
    vs_path = os.path.join(app_config.VECTOR_STORES_DIR, kb_name)
    
    try:
        # ç®€å•çš„ç´¢å¼•æ„å»ºé€»è¾‘
        print(f"å¼€å§‹ä¸ºçŸ¥è¯†åº“ '{kb_name}' æ„å»ºç´¢å¼•...")
        
        # åˆ›å»ºä¸€ä¸ªç©ºçš„å‘é‡å­˜å‚¨
        dimension = 384  # all-MiniLM-L6-v2çš„ç»´åº¦
        index = faiss.IndexFlatL2(dimension)
        vector_store = FaissVectorStore(faiss_index=index)
        storage_context = StorageContext.from_defaults(vector_store=vector_store)
        
        # åˆ›å»ºç©ºç´¢å¼•
        index = VectorStoreIndex.from_documents([], storage_context=storage_context)
        
        # ä¿å­˜ç´¢å¼•
        index.storage_context.persist(persist_dir=vs_path)
        
        return f"çŸ¥è¯†åº“ '{kb_name}' ç´¢å¼•æ„å»ºæˆåŠŸ"
    except Exception as e:
        return f"ç´¢å¼•æ„å»ºå¤±è´¥: {e}"

# å¯¹è¯å‡½æ•°
def chat_with_rag(query, kb_name, chat_history):
    """ä¸RAGç³»ç»Ÿå¯¹è¯"""
    if not kb_name:
        return "è¯·é€‰æ‹©çŸ¥è¯†åº“", chat_history
    
    if not query:
        return "è¯·è¾“å…¥æŸ¥è¯¢å†…å®¹", chat_history
    
    try:
        # ç®€å•çš„å“åº”é€»è¾‘
        response = f"è¿™æ˜¯å¯¹ '{query}' çš„å“åº”ï¼Œä½¿ç”¨çŸ¥è¯†åº“ '{kb_name}'"
        chat_history.append((query, response))
        return response, chat_history
    except Exception as e:
        return f"å¯¹è¯å¤±è´¥: {e}", chat_history

def clear_chat(chat_history):
    """æ¸…ç©ºå¯¹è¯å†å²"""
    return "", []

# å¯¼å…¥Gradioå¹¶åˆ›å»ºç•Œé¢
def create_gradio_interface():
    """åˆ›å»ºGradioç•Œé¢"""
    try:
        import gradio as gr
        
        # è‡ªå®šä¹‰CSSæ ·å¼
        custom_css = """
        #app-container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
        }
        
        #header-container {
            text-align: center;
            margin-bottom: 20px;
            padding: 20px;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            border-radius: 10px;
        }
        
        .kb-control-btn {
            margin: 5px;
        }
        
        .kb-dropdown {
            margin: 5px;
        }
        """
        
        # JavaScriptä»£ç 
        js_code = """
        <script>
        // æ·»åŠ é¡µé¢åŠ è½½åŠ¨ç”»
        window.addEventListener('load', function() {
            console.log('åŒ»ç–—çŸ¥è¯†é—®ç­”ç³»ç»Ÿå·²åŠ è½½å®Œæˆ');
        });
        </script>
        """
        
        # åˆ›å»ºç•Œé¢
        with gr.Blocks(title="åŒ»ç–—çŸ¥è¯†é—®ç­”ç³»ç»Ÿ", 
                      theme=gr.themes.Soft(primary_hue="blue", secondary_hue="blue"),
                      css=custom_css, elem_id="app-container") as demo:
            
            # é¡µé¢æ ‡é¢˜
            with gr.Column(elem_id="header-container"):
                gr.Markdown("""
                # ğŸ¥ åŒ»ç–—çŸ¥è¯†é—®ç­”ç³»ç»Ÿ
                **æ™ºèƒ½åŒ»ç–—åŠ©æ‰‹ï¼Œæ”¯æŒå¤šçŸ¥è¯†åº“ç®¡ç†ã€å¤šè½®å¯¹è¯ã€æ™®é€šè¯­ä¹‰æ£€ç´¢å’Œé«˜çº§å¤šè·³æ¨ç†**  
                æœ¬ç³»ç»Ÿæ”¯æŒåˆ›å»ºå¤šä¸ªçŸ¥è¯†åº“ï¼Œä¸Šä¼ TXTæˆ–PDFæ–‡ä»¶ï¼Œé€šè¿‡è¯­ä¹‰å‘é‡æ£€ç´¢æˆ–åˆ›æ–°çš„å¤šè·³æ¨ç†æœºåˆ¶æä¾›åŒ»ç–—ä¿¡æ¯æŸ¥è¯¢æœåŠ¡ã€‚
                """)
            
            # JavaScriptä»£ç 
            gr.HTML(js_code, visible=False)
            
            # å¯¹è¯å†å²çŠ¶æ€
            chat_history_state = gr.State([])
            
            # æ ‡ç­¾é¡µ
            with gr.Tabs():
                # çŸ¥è¯†åº“ç®¡ç†æ ‡ç­¾
                with gr.TabItem("çŸ¥è¯†åº“ç®¡ç†"):
                    with gr.Row():
                        # çŸ¥è¯†åº“æ“ä½œåˆ—
                        with gr.Column(scale=1):
                            with gr.Row():
                                kb_name_input = gr.Textbox(label="æ–°çŸ¥è¯†åº“åç§°", placeholder="è¾“å…¥çŸ¥è¯†åº“åç§°...")
                                create_kb_btn = gr.Button("åˆ›å»ºçŸ¥è¯†åº“", variant="primary", elem_classes="kb-control-btn")
                            
                            with gr.Row():
                                delete_kb_dropdown = gr.Dropdown(label="é€‰æ‹©è¦åˆ é™¤çš„çŸ¥è¯†åº“", 
                                                               choices=get_knowledge_bases(), 
                                                               elem_classes="kb-dropdown")
                                delete_kb_btn = gr.Button("åˆ é™¤çŸ¥è¯†åº“", variant="secondary", elem_classes="kb-control-btn")
                            
                            with gr.Row():
                                files_input = gr.File(label="ä¸Šä¼ æ–‡ä»¶", file_types=[".txt", ".pdf", ".docx"], multiple=True)
                                upload_btn = gr.Button("ä¸Šä¼ æ–‡ä»¶", variant="secondary", elem_classes="kb-control-btn")
                            
                            with gr.Row():
                                build_kb_dropdown = gr.Dropdown(label="é€‰æ‹©è¦æ„å»ºç´¢å¼•çš„çŸ¥è¯†åº“", 
                                                              choices=get_knowledge_bases(), 
                                                              elem_classes="kb-dropdown")
                                build_index_btn = gr.Button("æ„å»ºç´¢å¼•", variant="primary", elem_classes="kb-control-btn")
                            
                            # çŠ¶æ€è¾“å‡º
                            status_output = gr.Textbox(label="æ“ä½œçŠ¶æ€", interactive=False, lines=3)
                        
                        # çŸ¥è¯†åº“ä¿¡æ¯åˆ—
                        with gr.Column(scale=2):
                            gr.Markdown("## çŸ¥è¯†åº“åˆ—è¡¨")
                            kb_list = gr.Dataframe(
                                headers=["çŸ¥è¯†åº“åç§°", "åˆ›å»ºæ—¶é—´", "æ–‡ä»¶æ•°é‡"],
                                datatype=["str", "str", "number"],
                                value=[["ç¤ºä¾‹çŸ¥è¯†åº“", "2023-12-01", 5]]
                            )
                    
                    # æŒ‰é’®äº‹ä»¶
                    create_kb_btn.click(fn=create_knowledge_base, inputs=[kb_name_input], outputs=[status_output])
                    delete_kb_btn.click(fn=delete_knowledge_base, inputs=[delete_kb_dropdown], outputs=[status_output])
                    upload_btn.click(fn=process_uploaded_files, inputs=[delete_kb_dropdown, files_input], outputs=[status_output])
                    build_index_btn.click(fn=build_index, inputs=[build_kb_dropdown], outputs=[status_output])
                
                # æ™®é€šæ£€ç´¢æ ‡ç­¾
                with gr.TabItem("æ™®é€šè¯­ä¹‰æ£€ç´¢"):
                    with gr.Row():
                        with gr.Column(scale=1):
                            retrieval_kb_dropdown = gr.Dropdown(label="é€‰æ‹©çŸ¥è¯†åº“", 
                                                              choices=get_knowledge_bases(), 
                                                              elem_classes="kb-dropdown")
                        with gr.Column(scale=2):
                            retrieval_query = gr.Textbox(label="æ£€ç´¢æŸ¥è¯¢", placeholder="è¾“å…¥æ‚¨çš„é—®é¢˜...", lines=2)
                    
                    with gr.Row():
                        retrieve_btn = gr.Button("å¼€å§‹æ£€ç´¢", variant="primary")
                    
                    with gr.Row():
                        retrieval_result = gr.Textbox(label="æ£€ç´¢ç»“æœ", interactive=False, lines=10)
                    
                    retrieve_btn.click(fn=chat_with_rag, 
                                      inputs=[retrieval_query, retrieval_kb_dropdown, chat_history_state],
                                      outputs=[retrieval_result, chat_history_state])
                
                # å¤šè½®å¯¹è¯æ ‡ç­¾
                with gr.TabItem("å¤šè½®å¯¹è¯"):
                    with gr.Row():
                        with gr.Column(scale=1):
                            chat_kb_dropdown = gr.Dropdown(label="é€‰æ‹©çŸ¥è¯†åº“", 
                                                          choices=get_knowledge_bases(), 
                                                          elem_classes="kb-dropdown")
                        with gr.Column(scale=2):
                            chat_input = gr.Textbox(label="è¾“å…¥æ‚¨çš„é—®é¢˜", placeholder="è¾“å…¥æ‚¨çš„é—®é¢˜...", lines=2)
                            with gr.Row():
                                send_btn = gr.Button("å‘é€", variant="primary")
                                clear_btn = gr.Button("æ¸…ç©ºå¯¹è¯")
                    
                    with gr.Row():
                        chat_output = gr.Chatbot(label="å¯¹è¯å†å²", height=500)
                    
                    send_btn.click(fn=chat_with_rag, 
                                  inputs=[chat_input, chat_kb_dropdown, chat_output],
                                  outputs=[chat_input, chat_output])
                    clear_btn.click(fn=clear_chat, inputs=[chat_output], outputs=[chat_input, chat_output])
                
                # å¤šè·³æ¨ç†æ ‡ç­¾
                with gr.TabItem("é«˜çº§å¤šè·³æ¨ç†"):
                    with gr.Row():
                        with gr.Column(scale=1):
                            multi_hop_kb_dropdown = gr.Dropdown(label="é€‰æ‹©çŸ¥è¯†åº“", 
                                                               choices=get_knowledge_bases(), 
                                                               elem_classes="kb-dropdown")
                        with gr.Column(scale=2):
                            multi_hop_query = gr.Textbox(label="å¤šè·³æ¨ç†æŸ¥è¯¢", placeholder="è¾“å…¥å¤æ‚çš„å¤šè·³é—®é¢˜...", lines=3)
                    
                    with gr.Row():
                        multi_hop_btn = gr.Button("å¼€å§‹å¤šè·³æ¨ç†", variant="primary")
                    
                    with gr.Row():
                        multi_hop_result = gr.Textbox(label="å¤šè·³æ¨ç†ç»“æœ", interactive=False, lines=15)
                    
                    multi_hop_btn.click(fn=chat_with_rag, 
                                       inputs=[multi_hop_query, multi_hop_kb_dropdown, chat_history_state],
                                       outputs=[multi_hop_result, chat_history_state])
        
        return demo
    
    except Exception as e:
        print(f"åˆ›å»ºGradioç•Œé¢å¤±è´¥: {type(e).__name__}: {e}")
        import traceback
        traceback.print_exc()
        return None

# ä¸»å‡½æ•°
def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("ğŸ¥ åŒ»ç–—çŸ¥è¯†é—®ç­”ç³»ç»Ÿ (Medi-RAG)")
    print("=" * 60)
    
    # åˆ›å»ºGradioç•Œé¢
    print(f"[{time.strftime('%H:%M:%S')}] å¼€å§‹åˆ›å»ºGradioç•Œé¢...")
    demo = create_gradio_interface()
    
    if demo is None:
        print("Gradioç•Œé¢åˆ›å»ºå¤±è´¥ï¼Œç¨‹åºé€€å‡º")
        sys.exit(1)
    
    # å¯åŠ¨æœåŠ¡
    try:
        server_port = 7860
        print(f"[{time.strftime('%H:%M:%S')}] âœ“ Gradioç•Œé¢åˆ›å»ºæˆåŠŸï¼Œæ­£åœ¨å¯åŠ¨æœåŠ¡...")
        print(f"[{time.strftime('%H:%M:%S')}] ğŸŒ æœåŠ¡åœ°å€: http://localhost:{server_port}")
        print(f"[{time.strftime('%H:%M:%S')}] ğŸŒ å±€åŸŸç½‘åœ°å€: http://0.0.0.0:{server_port}")
        print("=" * 60)
        print(f"[{time.strftime('%H:%M:%S')}] ç³»ç»Ÿå·²å¯åŠ¨ï¼Œæ‚¨å¯ä»¥é€šè¿‡æµè§ˆå™¨è®¿é—®ä¸Šè¿°åœ°å€ä½¿ç”¨ç³»ç»Ÿ")
        
        demo.launch(server_name="0.0.0.0", server_port=server_port, share=False)
        
    except Exception as e:
        print(f"[{time.strftime('%H:%M:%S')}] âœ— å¯åŠ¨æœåŠ¡å¤±è´¥: {type(e).__name__}: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

if __name__ == "__main__":
    main()