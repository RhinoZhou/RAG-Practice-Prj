#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
OCRä¸ç‰ˆé¢å¯¹é½å·¥å…·
åŠŸèƒ½ï¼šå¯¹PDFæˆ–å›¾åƒæ–‡ä»¶è¿›è¡ŒOCRè¯†åˆ«ï¼Œå¹¶è¿›è¡Œç‰ˆé¢å¯¹é½
æµç¨‹ï¼šå‰å¤„ç†ï¼ˆå»å™ª/æ—‹è½¬/äºŒå€¼åŒ–ï¼‰â†’ PaddleOCR â†’ æ®µè½åˆå¹¶ â†’ ç‰ˆé¢å¯¹é½ï¼ˆå›¾æ–‡æ¡†å¯¹é½ï¼‰
è¾“å‡ºï¼šæ®µè½æ–‡æœ¬ + ç‰ˆé¢å…ƒç´ åæ ‡

ä½¿ç”¨è¯´æ˜ï¼š
1. å®‰è£…ä¾èµ–ï¼špip install paddlepaddle paddleocr opencv-python pillow numpy
2. è¿è¡Œç¤ºä¾‹ï¼špython 09-ocr_pipeline.py --input_file data/your_file.pdf --output_dir ./ocr_output

å…³é”®ç‚¹ï¼š
- å­—ç¬¦å‡†ç¡®ç‡è¯„ä¼°ï¼šè®¡ç®—OCRè¯†åˆ«ç»“æœçš„ç½®ä¿¡åº¦
- å€¾æ–œè§’æ ¡æ­£ï¼šè‡ªåŠ¨æ£€æµ‹å¹¶æ ¡æ­£å›¾åƒå€¾æ–œ
- ç‰ˆé¢å…ƒç´ å‘½åï¼šä¸ºä¸åŒç±»å‹çš„ç‰ˆé¢å…ƒç´ ï¼ˆæ ‡é¢˜ã€æ­£æ–‡ã€å›¾ç‰‡ã€è¡¨æ ¼ç­‰ï¼‰åˆ†é…å”¯ä¸€æ ‡è¯†ç¬¦
"""

# å¯¼å…¥åŸºç¡€åº“
import os
import json
import logging
import argparse
import sys
import subprocess
from typing import List, Dict, Any, Tuple, Optional

# å°è¯•å¯¼å…¥ä¸»è¦ä¾èµ–ï¼Œå¦‚æœå¤±è´¥åˆ™æä¾›å‹å¥½çš„é”™è¯¯ä¿¡æ¯
packages_available = {
    'cv2': False,
    'numpy': False,
    'PIL': False,
    'paddleocr': False,
    'pdfplumber': False
}

def check_dependencies():
    """æ£€æŸ¥å¹¶å°è¯•å®‰è£…å¿…è¦çš„ä¾èµ–åŒ…"""
    try:
        import cv2
        packages_available['cv2'] = True
    except ImportError:
        pass
        
    try:
        import numpy
        packages_available['numpy'] = True
    except ImportError:
        pass
        
    try:
        from PIL import Image
        packages_available['PIL'] = True
    except ImportError:
        pass
        
    try:
        import paddleocr
        packages_available['paddleocr'] = True
    except ImportError as e:
        print(f"è­¦å‘Šï¼šæ— æ³•å¯¼å…¥paddleocr: {e}")
        print("è¿™å¯èƒ½æ˜¯ç”±äºPythonç‰ˆæœ¬ä¸PyTorchä¸å…¼å®¹å¯¼è‡´çš„")
        print("å»ºè®®ä½¿ç”¨Python 3.8-3.11ç‰ˆæœ¬ï¼Œè¿™äº›ç‰ˆæœ¬ä¸PyTorchæœ‰æ›´å¥½çš„å…¼å®¹æ€§")
        
    try:
        import pdfplumber
        packages_available['pdfplumber'] = True
    except ImportError:
        pass

    # å®‰è£…ç¼ºå¤±çš„ä¾èµ–
    required_packages = []
    if not packages_available['cv2']:
        required_packages.append('opencv-python>=4.8.0')
    if not packages_available['numpy']:
        required_packages.append('numpy>=1.24.0')
    if not packages_available['PIL']:
        required_packages.append('pillow>=9.5.0')
    if not packages_available['pdfplumber']:
        required_packages.append('pdfplumber>=0.9.0')
    
    # æ³¨æ„ï¼šç”±äºPaddleOCRä¾èµ–é—®é¢˜ï¼Œæˆ‘ä»¬ä¸è‡ªåŠ¨å®‰è£…å®ƒ
    if required_packages:
        print(f"æ£€æµ‹åˆ°ç¼ºå°‘ä»¥ä¸‹åŸºç¡€ä¾èµ–åŒ…ï¼š{required_packages}")
        print("æ­£åœ¨è‡ªåŠ¨å®‰è£…åŸºç¡€ä¾èµ–åŒ…ï¼Œè¯·ç¨å€™...")
        try:
            subprocess.check_call([sys.executable, '-m', 'pip', 'install', *required_packages])
            print("åŸºç¡€ä¾èµ–åŒ…å®‰è£…æˆåŠŸï¼")
            # é‡æ–°å¯¼å…¥
            check_dependencies()
        except subprocess.CalledProcessError:
            print("è­¦å‘Šï¼šè‡ªåŠ¨å®‰è£…åŸºç¡€ä¾èµ–åŒ…å¤±è´¥ï¼Œè¯·æ‰‹åŠ¨è¿è¡Œä»¥ä¸‹å‘½ä»¤å®‰è£…ï¼š")
            print(f"pip install {' '.join(required_packages)}")
            print("ç¨‹åºå¯èƒ½æ— æ³•æ­£å¸¸è¿è¡Œã€‚")

# æ£€æŸ¥ä¾èµ–
check_dependencies()

# å°è¯•å¯¼å…¥å…¶ä½™å¿…è¦çš„åº“
try:
    import cv2
    import numpy as np
    from PIL import Image
    import pdfplumber
    # åªåœ¨paddleocrå¯ç”¨æ—¶å¯¼å…¥
    if packages_available['paddleocr']:
        import paddleocr
    else:
        paddleocr = None
except ImportError as e:
    print(f"å¯¼å…¥å¿…è¦çš„åº“å¤±è´¥: {e}")

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.DEBUG,  # è®¾ç½®ä¸ºDEBUGçº§åˆ«ä»¥æŸ¥çœ‹è¯¦ç»†çš„è°ƒè¯•ä¿¡æ¯
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler("ocr_pipeline_log.txt"),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger('OCRPipeline')

class ImagePreprocessor:
    """å›¾åƒå‰å¤„ç†å™¨ï¼Œè´Ÿè´£å»å™ªã€æ—‹è½¬æ ¡æ­£å’ŒäºŒå€¼åŒ–ç­‰æ“ä½œ"""
    
    def __init__(self, config: Dict[str, Any] = None):
        """åˆå§‹åŒ–å›¾åƒå‰å¤„ç†å™¨"""
        self.default_config = {
            'denoise_strength': 1.0,
            'blur_kernel_size': (5, 5),
            'binary_threshold': 127,
            'max_rotation_angle': 15.0
        }
        self.config = self.default_config.copy()
        if config:
            self.config.update(config)
    
    def load_image(self, file_path: str) -> Optional[np.ndarray]:
        """åŠ è½½å›¾åƒæ–‡ä»¶æˆ–PDFæ–‡ä»¶çš„ç¬¬ä¸€é¡µä¸ºå›¾åƒ"""
        try:
            if file_path.lower().endswith('.pdf'):
                # å¤„ç†PDFæ–‡ä»¶ï¼Œä»…æå–ç¬¬ä¸€é¡µ
                print(f"ğŸ“„  æ£€æµ‹åˆ°PDFæ–‡ä»¶: {file_path}")
                print("ğŸ”  ä½¿ç”¨pdfplumberåŠ è½½PDFå¹¶æå–ç¬¬ä¸€é¡µ...")
                with pdfplumber.open(file_path) as pdf:
                    if not pdf.pages:
                        logger.error(f"PDFæ–‡ä»¶ä¸ºç©º: {file_path}")
                        print("âŒ  PDFæ–‡ä»¶ä¸ºç©ºï¼Œæ— æ³•æå–å†…å®¹")
                        return None
                    print(f"ğŸ“‘  PDFåŒ…å«{len(pdf.pages)}é¡µï¼Œå°†å¤„ç†ç¬¬ä¸€é¡µ")
                    first_page = pdf.pages[0]
                    print("ğŸ“¸  å°†PDFé¡µé¢è½¬æ¢ä¸ºå›¾åƒï¼Œåˆ†è¾¨ç‡è®¾ç½®ä¸º300DPI...")
                    img = np.array(first_page.to_image(resolution=300).original)
                    print("âœ…  PDFé¡µé¢è½¬æ¢æˆåŠŸ")
                    return img
            else:
                # å¤„ç†å›¾åƒæ–‡ä»¶
                print(f"ğŸ–¼ï¸  æ£€æµ‹åˆ°å›¾åƒæ–‡ä»¶: {file_path}")
                img = cv2.imread(file_path)
                if img is None:
                    logger.error(f"æ— æ³•åŠ è½½å›¾åƒæ–‡ä»¶: {file_path}")
                    print(f"âŒ  æ— æ³•åŠ è½½å›¾åƒæ–‡ä»¶: {file_path}")
                    return None
                print(f"âœ…  å›¾åƒåŠ è½½æˆåŠŸï¼Œå°ºå¯¸: {img.shape[1]}x{img.shape[0]}")
                return img
        except Exception as e:
            logger.error(f"åŠ è½½æ–‡ä»¶æ—¶å‡ºé”™: {e}")
            print(f"âš ï¸  åŠ è½½æ–‡ä»¶æ—¶å‡ºé”™: {type(e).__name__}: {e}")
            return None
    
    def denoise(self, image: np.ndarray) -> np.ndarray:
        """å›¾åƒå»å™ªå¤„ç†"""
        # ä½¿ç”¨é«˜æ–¯æ¨¡ç³Šå»å™ª
        blurred = cv2.GaussianBlur(image, self.config['blur_kernel_size'], 0)
        return blurred
    
    def detect_rotation_angle(self, image: np.ndarray) -> float:
        """æ£€æµ‹å›¾åƒå€¾æ–œè§’åº¦"""
        # è½¬æ¢ä¸ºç°åº¦å›¾
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) if len(image.shape) == 3 else image
        
        # äºŒå€¼åŒ–
        _, binary = cv2.threshold(gray, self.config['binary_threshold'], 255, cv2.THRESH_BINARY_INV)
        
        # æŸ¥æ‰¾è½®å»“
        contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        if not contours:
            return 0.0
        
        # è®¡ç®—æœ€å°å¤–æ¥çŸ©å½¢ï¼Œæ‰¾å‡ºæ—‹è½¬è§’åº¦
        angles = []
        for contour in contours:
            if cv2.contourArea(contour) > 100:
                rect = cv2.minAreaRect(contour)
                angle = rect[2]
                # è°ƒæ•´è§’åº¦èŒƒå›´
                if angle < -45:
                    angle += 90
                angles.append(angle)
        
        # è¿”å›å¹³å‡è§’åº¦
        return np.mean(angles) if angles else 0.0
    
    def correct_rotation(self, image: np.ndarray, angle: float) -> np.ndarray:
        """æ ¡æ­£å›¾åƒå€¾æ–œ"""
        if abs(angle) < 0.5:  # è§’åº¦å¤ªå°ï¼Œä¸éœ€è¦æ ¡æ­£
            return image
        
        # é™åˆ¶æœ€å¤§æ—‹è½¬è§’åº¦
        angle = max(-self.config['max_rotation_angle'], min(self.config['max_rotation_angle'], angle))
        
        # è·å–å›¾åƒä¸­å¿ƒç‚¹
        h, w = image.shape[:2]
        center = (w // 2, h // 2)
        
        # è®¡ç®—æ—‹è½¬çŸ©é˜µ
        M = cv2.getRotationMatrix2D(center, angle, 1.0)
        
        # æ‰§è¡Œæ—‹è½¬ï¼Œä¿æŒå›¾åƒå°ºå¯¸ä¸å˜
        rotated = cv2.warpAffine(image, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)
        
        return rotated
    
    def binarize(self, image: np.ndarray) -> np.ndarray:
        """å›¾åƒäºŒå€¼åŒ–å¤„ç†"""
        # è½¬æ¢ä¸ºç°åº¦å›¾
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) if len(image.shape) == 3 else image
        
        # è‡ªé€‚åº”é˜ˆå€¼äºŒå€¼åŒ–
        binary = cv2.adaptiveThreshold(
            gray, 255, 
            cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
            cv2.THRESH_BINARY, 
            11, 2
        )
        
        return binary
    
    def preprocess(self, file_path: str) -> Tuple[Optional[np.ndarray], float]:
        """å®Œæ•´çš„é¢„å¤„ç†æµç¨‹"""
        # åŠ è½½å›¾åƒ
        image = self.load_image(file_path)
        if image is None:
            return None, 0.0
        
        # å»å™ª
        denoised = self.denoise(image)
        
        # æ£€æµ‹å€¾æ–œè§’åº¦
        rotation_angle = self.detect_rotation_angle(denoised)
        
        # æ ¡æ­£å€¾æ–œ
        rotated = self.correct_rotation(denoised, rotation_angle)
        
        # äºŒå€¼åŒ–
        binary = self.binarize(rotated)
        
        return binary, rotation_angle

class OCRProcessor:
    """OCRå¤„ç†å™¨ï¼Œä½¿ç”¨PaddleOCRè¿›è¡Œæ–‡æœ¬è¯†åˆ«"""
    
    def __init__(self, config: Dict[str, Any] = None):
        """åˆå§‹åŒ–OCRå¤„ç†å™¨"""
        self.default_config = {
            'lang': 'ch',  # è¯­è¨€ï¼Œ'ch'è¡¨ç¤ºä¸­æ–‡
            'text_det_thresh': 0.3,  # æ–‡æœ¬æ£€æµ‹é˜ˆå€¼ï¼ˆæ–°ç‰ˆå‚æ•°åï¼‰
            'text_recognition_batch_size': 6  # è¯†åˆ«æ‰¹æ¬¡å¤§å°ï¼ˆæ–°ç‰ˆå‚æ•°åï¼‰
        }
        self.config = self.default_config.copy()
        if config:
            self.config.update(config)
        
        # åˆå§‹åŒ–PaddleOCR
        self.ocr = None
        if paddleocr is not None:
            try:
                # ä½¿ç”¨æ–°ç‰ˆPaddleOCRçš„å‚æ•°å
                ocr_args = {
                    'lang': self.config['lang']
                }
                
                # æ£€æµ‹é˜ˆå€¼å‚æ•°
                if 'text_det_thresh' in self.config:
                    ocr_args['text_det_thresh'] = self.config['text_det_thresh']
                
                # è¯†åˆ«æ‰¹æ¬¡å¤§å°å‚æ•°
                if 'text_recognition_batch_size' in self.config:
                    ocr_args['text_recognition_batch_size'] = self.config['text_recognition_batch_size']
                
                # æ³¨æ„ï¼šæ–°ç‰ˆPaddleOCRå·²ç»ä¸éœ€è¦æ˜¾å¼è®¾ç½®use_gpuå‚æ•°
                
                self.ocr = paddleocr.PaddleOCR(**ocr_args)
                logger.info("PaddleOCRåˆå§‹åŒ–æˆåŠŸ")
            except Exception as e:
                logger.error(f"PaddleOCRåˆå§‹åŒ–å¤±è´¥: {e}")
                self.ocr = None
        else:
            logger.warning("PaddleOCRä¸å¯ç”¨ï¼Œæ— æ³•è¿›è¡ŒOCRè¯†åˆ«")
    
    def recognize(self, image: np.ndarray) -> List[Dict[str, Any]]:
        """ä½¿ç”¨PaddleOCRè¿›è¡Œæ–‡æœ¬è¯†åˆ«ï¼Œå®Œå…¨é€‚é…æ–°ç‰ˆPaddleOCRçš„è¿”å›æ ¼å¼
        
        Args:
            image: é¢„å¤„ç†åçš„å›¾åƒæ•°æ®ï¼ˆnumpyæ•°ç»„æ ¼å¼ï¼‰
            
        Returns:
            è¯†åˆ«åˆ°çš„æ–‡æœ¬ä¿¡æ¯åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å«æ–‡æœ¬å†…å®¹ã€ç½®ä¿¡åº¦å’Œä½ç½®ä¿¡æ¯
        """
        if self.ocr is None:
            logger.error("OCRå¼•æ“æœªåˆå§‹åŒ–ï¼Œæ— æ³•è¿›è¡Œè¯†åˆ«")
            return []
        
        recognized_texts = []
        
        try:
            # æ­¥éª¤1: æ£€æŸ¥å›¾åƒæ ¼å¼å¹¶ç¡®ä¿æ˜¯RGBæ ¼å¼
            print("ğŸ”  å¼€å§‹æ£€æŸ¥å›¾åƒæ ¼å¼...")
            if len(image.shape) == 2:
                # äºŒå€¼åŒ–å›¾åƒæˆ–ç°åº¦å›¾åƒï¼Œè½¬æ¢ä¸ºRGB
                print("ğŸ“·  æ£€æµ‹åˆ°äºŒå€¼åŒ–/ç°åº¦å›¾åƒï¼Œè½¬æ¢ä¸ºRGBæ ¼å¼...")
                image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)
            elif len(image.shape) == 3 and image.shape[2] == 4:
                # RGBAå›¾åƒï¼Œè½¬æ¢ä¸ºRGB
                print("ğŸ“·  æ£€æµ‹åˆ°RGBAå›¾åƒï¼Œè½¬æ¢ä¸ºRGBæ ¼å¼...")
                image = cv2.cvtColor(image, cv2.COLOR_RGBA2RGB)
            elif len(image.shape) == 3 and image.shape[2] == 3:
                print("âœ…  å›¾åƒå·²æ˜¯RGBæ ¼å¼ï¼Œæ— éœ€è½¬æ¢")
            print(f"ğŸ“  å¤„ç†åå›¾åƒå°ºå¯¸: {image.shape[1]}x{image.shape[0]}")
            
            # æ­¥éª¤2: æ‰§è¡ŒOCRè¯†åˆ«ï¼Œä½¿ç”¨æœ€æ–°çš„predictæ–¹æ³•
            print("ğŸ¤–  æ‰§è¡ŒOCRè¯†åˆ«ï¼Œè°ƒç”¨predictæ–¹æ³•...")
            result = self.ocr.predict(image)
            print("âœ…  OCRè¯†åˆ«æ‰§è¡Œå®Œæˆ")
            
            # æ­¥éª¤3: åŸºç¡€ç±»å‹æ£€æŸ¥
            if result is None:
                logger.warning("OCRè¿”å›ç»“æœä¸ºç©º")
                print("âš ï¸  OCRè¿”å›ç»“æœä¸ºç©º")
                return recognized_texts
            
            print(f"===== OCRè°ƒè¯• - ç»“æœç±»å‹: {type(result)} ====")
            
            # æ­¥éª¤4: é€‚é…æ–°ç‰ˆPaddleOCRçš„è¿”å›æ ¼å¼
            # ä»æµ‹è¯•ç»“æœå¯ä»¥çœ‹å‡ºï¼Œæ–°ç‰ˆPaddleOCRè¿”å›çš„æ˜¯ä¸€ä¸ªåŒ…å«å­—å…¸çš„åˆ—è¡¨
            print("ğŸ”  å¼€å§‹è§£æOCRç»“æœ...")
            if isinstance(result, list) and len(result) > 0:
                # è·å–ç¬¬ä¸€ä¸ªå…ƒç´ ï¼ˆé€šå¸¸æ˜¯ä¸»è¦çš„OCRç»“æœï¼‰
                ocr_result = result[0]
                
                # æ£€æŸ¥æ˜¯å¦åŒ…å«è¯†åˆ«çš„æ–‡æœ¬å’Œç½®ä¿¡åº¦
                if isinstance(ocr_result, dict) and 'rec_texts' in ocr_result and 'rec_scores' in ocr_result and 'dt_polys' in ocr_result:
                    print(f"âœ…  æ£€æµ‹åˆ°æ–°ç‰ˆPaddleOCRæ ¼å¼ï¼ŒåŒ…å«rec_texts, rec_scoreså’Œdt_polys")
                    
                    # è·å–è¯†åˆ«çš„æ–‡æœ¬ã€ç½®ä¿¡åº¦å’Œè¾¹ç•Œæ¡†
                    texts = ocr_result['rec_texts']
                    scores = ocr_result['rec_scores']
                    bboxes = ocr_result['dt_polys']
                    
                    # ç¡®ä¿ä¸‰ä¸ªåˆ—è¡¨é•¿åº¦ä¸€è‡´
                    min_len = min(len(texts), len(scores), len(bboxes))
                    print(f"ğŸ“Š  è¯†åˆ«åˆ°{min_len}ä¸ªæ–‡æœ¬åŒºåŸŸ")
                    
                    # å¤„ç†æ¯ä¸ªè¯†åˆ«çš„æ–‡æœ¬åŒºåŸŸ
                    print("ğŸ”§  å¼€å§‹å¤„ç†è¯†åˆ«åˆ°çš„æ–‡æœ¬åŒºåŸŸ...")
                    for i in range(min_len):
                        try:
                            text = texts[i]
                            confidence = scores[i]
                            bbox = bboxes[i]
                            
                            # æ£€æŸ¥å¹¶å¤„ç†è¾¹ç•Œæ¡†åæ ‡
                            if isinstance(bbox, np.ndarray):
                                # å°†numpyæ•°ç»„è½¬æ¢ä¸ºåˆ—è¡¨
                                bbox_list = bbox.tolist()
                            elif isinstance(bbox, (list, tuple)):
                                bbox_list = list(bbox)
                            else:
                                print(f"âš ï¸  è·³è¿‡æ— æ•ˆçš„è¾¹ç•Œæ¡†ç±»å‹: {type(bbox)}")
                                continue
                            
                            # è®¡ç®—è¾¹ç•Œæ¡†åæ ‡
                            try:
                                x_coords = []
                                y_coords = []
                                
                                # å¤„ç†è¾¹ç•Œæ¡†ç‚¹ï¼ˆå¯èƒ½æ˜¯numpyæ•°ç»„ï¼‰
                                for point in bbox_list:
                                    if isinstance(point, np.ndarray):
                                        # å¯¹äºnumpyæ•°ç»„æ ¼å¼çš„ç‚¹
                                        if len(point) >= 2:
                                            x_coords.append(float(point[0]))
                                            y_coords.append(float(point[1]))
                                    elif isinstance(point, (list, tuple)) and len(point) >= 2:
                                        # å¯¹äºåˆ—è¡¨æˆ–å…ƒç»„æ ¼å¼çš„ç‚¹
                                        x_coords.append(float(point[0]))
                                        y_coords.append(float(point[1]))
                                
                                if x_coords and y_coords:
                                    # è®¡ç®—ä¸­å¿ƒç‚¹
                                    center_x = sum(x_coords) / len(x_coords)
                                    center_y = sum(y_coords) / len(y_coords)
                                    
                                    # æ·»åŠ è¯†åˆ«çš„æ–‡æœ¬ä¿¡æ¯
                                    recognized_texts.append({
                                        'bbox': {
                                            'x0': min(x_coords),
                                            'y0': min(y_coords),
                                            'x1': max(x_coords),
                                            'y1': max(y_coords),
                                            'points': bbox_list
                                        },
                                        'center': {
                                            'x': center_x,
                                            'y': center_y
                                        },
                                        'text': str(text) if text else "",
                                        'confidence': float(confidence) if confidence else 0.0
                                    })
                            except Exception as coord_err:
                                print(f"âš ï¸  è§£æè¾¹ç•Œæ¡†åæ ‡å‡ºé”™: {coord_err}")
                                continue
                        except Exception as item_err:
                            print(f"âš ï¸  è§£æå•ä¸ªOCRé¡¹ç›®å‡ºé”™: {item_err}")
                            continue
                else:
                    print("âŒ  OCRç»“æœä¸åŒ…å«é¢„æœŸçš„é”®ï¼Œå°è¯•å…¶ä»–è§£ææ–¹å¼")
                    # æ‰“å°ç»“æœçš„é”®ï¼Œå¸®åŠ©è°ƒè¯•
                    if isinstance(ocr_result, dict):
                        print(f"   å¯ç”¨é”®: {ocr_result.keys()}")
            else:
                print(f"âŒ  OCRè¿”å›çš„ä¸æ˜¯é¢„æœŸçš„åˆ—è¡¨æ ¼å¼ï¼Œç»“æœ: {str(result)[:200]}")
            
            print(f"âœ…  æ–‡æœ¬å—è§£æå®Œæˆï¼ŒæˆåŠŸè§£æ{len(recognized_texts)}ä¸ªæ–‡æœ¬å—")
            
            # æ˜¾ç¤ºå‰å‡ ä¸ªè¯†åˆ«ç»“æœä½œä¸ºé¢„è§ˆ
            if recognized_texts:
                preview_count = min(3, len(recognized_texts))
                print(f"ğŸ”  å‰{preview_count}ä¸ªè¯†åˆ«ç»“æœé¢„è§ˆ:")
                for i in range(preview_count):
                    text_info = recognized_texts[i]
                    print(f"   [{i+1}] '{text_info['text'][:30]}{'...' if len(text_info['text']) > 30 else ''}' (ç½®ä¿¡åº¦: {text_info['confidence']:.4f})")
            
            # å¦‚æœæ²¡æœ‰è§£æåˆ°ä»»ä½•æ–‡æœ¬ï¼Œè®°å½•è¯¦ç»†çš„è°ƒè¯•ä¿¡æ¯
            if not recognized_texts:
                print(f"âŒ  æœªè§£æåˆ°ä»»ä½•æ–‡æœ¬ï¼Œå®Œæ•´OCRç»“æœç»“æ„:")
                print(f"   ç±»å‹: {type(result)}")
                if isinstance(result, list):
                    print(f"   åˆ—è¡¨é•¿åº¦: {len(result)}")
                    for i, item in enumerate(result):
                        print(f"   å…ƒç´ {i}: ç±»å‹={type(item)}")
                        if isinstance(item, dict):
                            print(f"     é”®: {item.keys()}")
            
            return recognized_texts
        
        except Exception as e:
            print(f"âŒ  OCRè¯†åˆ«è¿‡ç¨‹å‡ºé”™: {type(e).__name__}: {e}")
            print("ğŸ’¡  é”™è¯¯æ’æŸ¥å»ºè®®:")
            print("   1. æ£€æŸ¥PaddleOCRç‰ˆæœ¬æ˜¯å¦å…¼å®¹")
            print("   2. ç¡®è®¤å›¾åƒæ ¼å¼æ˜¯å¦æ­£ç¡®")
            print("   3. æ£€æŸ¥ç³»ç»Ÿèµ„æºæ˜¯å¦å……è¶³")
            logger.error(f"OCRè¯†åˆ«å‡ºé”™: {e}")
            
            # å³ä½¿å‡ºé”™ï¼Œä¹Ÿè¦è¿”å›å·²æˆåŠŸè§£æçš„æ–‡æœ¬å—ï¼ˆå¦‚æœæœ‰ï¼‰
            return recognized_texts
    
    def evaluate_accuracy(self, recognized_texts: List[Dict[str, Any]]) -> Dict[str, float]:
        """è¯„ä¼°OCRè¯†åˆ«å‡†ç¡®ç‡"""
        if not recognized_texts:
            return {
                'average_confidence': 0.0,
                'high_confidence_rate': 0.0,
                'low_confidence_count': 0
            }
        
        # è®¡ç®—å¹³å‡ç½®ä¿¡åº¦
        total_confidence = sum(text['confidence'] for text in recognized_texts)
        average_confidence = total_confidence / len(recognized_texts)
        
        # è®¡ç®—é«˜ç½®ä¿¡åº¦ï¼ˆ>0.9ï¼‰æ–‡æœ¬æ¯”ä¾‹
        high_confidence_count = sum(1 for text in recognized_texts if text['confidence'] > 0.9)
        high_confidence_rate = high_confidence_count / len(recognized_texts)
        
        # ç»Ÿè®¡ä½ç½®ä¿¡åº¦ï¼ˆ<0.5ï¼‰æ–‡æœ¬æ•°é‡
        low_confidence_count = sum(1 for text in recognized_texts if text['confidence'] < 0.5)
        
        return {
            'average_confidence': average_confidence,
            'high_confidence_rate': high_confidence_rate,
            'low_confidence_count': low_confidence_count
        }

class LayoutAligner:
    """ç‰ˆé¢å¯¹é½å™¨ï¼Œè´Ÿè´£æ®µè½åˆå¹¶å’Œç‰ˆé¢å¯¹é½"""
    
    def __init__(self, config: Dict[str, Any] = None):
        """åˆå§‹åŒ–ç‰ˆé¢å¯¹é½å™¨
        
        Args:
            config: ç‰ˆé¢å¯¹é½é…ç½®å‚æ•°
        """
        self.default_config = {
            'vertical_merge_threshold': 10.0,  # å‚ç›´æ–¹å‘åˆå¹¶é˜ˆå€¼ï¼ˆåƒç´ ï¼‰
            'horizontal_merge_threshold': 20.0,  # æ°´å¹³æ–¹å‘åˆå¹¶é˜ˆå€¼ï¼ˆåƒç´ ï¼‰
            'paragraph_min_words': 5,  # æ®µè½æœ€å°å­—æ•°
            'element_types': ['text', 'title', 'image', 'table', 'figure']  # æ”¯æŒçš„ç‰ˆé¢å…ƒç´ ç±»å‹
        }
        self.config = self.default_config.copy()
        if config:
            self.config.update(config)
    
    def merge_paragraphs(self, recognized_texts: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """åˆå¹¶ç›¸é‚»çš„æ–‡æœ¬å—ä¸ºæ®µè½
        
        Args:
            recognized_texts: è¯†åˆ«åˆ°çš„æ–‡æœ¬å—åˆ—è¡¨
            
        Returns:
            åˆå¹¶åçš„æ®µè½åˆ—è¡¨
        """
        if not recognized_texts:
            print("âŒ  æ²¡æœ‰å¯åˆå¹¶çš„æ–‡æœ¬å—")
            return []
        
        # æŒ‰ç…§Yåæ ‡ï¼ˆä»ä¸Šåˆ°ä¸‹ï¼‰å’ŒXåæ ‡ï¼ˆä»å·¦åˆ°å³ï¼‰æ’åºæ–‡æœ¬å—
        print(f"ğŸ”  å¼€å§‹åˆå¹¶æ–‡æœ¬å—ï¼Œå…±{len(recognized_texts)}ä¸ªæ–‡æœ¬å—")
        print("ğŸ“  æŒ‰é¡µé¢ä½ç½®æ’åºæ–‡æœ¬å—...")
        sorted_texts = sorted(recognized_texts, key=lambda x: (x['center']['y'], x['center']['x']))
        
        paragraphs = []
        current_paragraph = sorted_texts[0].copy()
        current_paragraph['texts'] = [current_paragraph.pop('text')]
        
        merge_count = 0  # åˆå¹¶è®¡æ•°
        
        for text_block in sorted_texts[1:]:
            # è®¡ç®—å‚ç›´è·ç¦»ï¼ˆåˆ¤æ–­æ˜¯å¦åœ¨åŒä¸€å‚ç›´åŒºåŸŸï¼‰
            vertical_distance = text_block['center']['y'] - current_paragraph['center']['y']
            
            # è®¡ç®—æ°´å¹³é‡å ï¼ˆåˆ¤æ–­æ˜¯å¦åœ¨åŒä¸€æ°´å¹³åŒºåŸŸï¼‰
            horizontal_overlap = max(0, min(text_block['bbox']['x1'], current_paragraph['bbox']['x1']) - 
                                     max(text_block['bbox']['x0'], current_paragraph['bbox']['x0']))
            
            # å¦‚æœå‚ç›´è·ç¦»å°äºé˜ˆå€¼ä¸”æœ‰æ°´å¹³é‡å ï¼Œåˆ™åˆå¹¶ä¸ºåŒä¸€æ®µè½
            if (vertical_distance < self.config['vertical_merge_threshold'] and 
                horizontal_overlap > self.config['horizontal_merge_threshold']):
                # æ›´æ–°æ®µè½è¾¹ç•Œæ¡†
                current_paragraph['bbox']['x0'] = min(current_paragraph['bbox']['x0'], text_block['bbox']['x0'])
                current_paragraph['bbox']['y0'] = min(current_paragraph['bbox']['y0'], text_block['bbox']['y0'])
                current_paragraph['bbox']['x1'] = max(current_paragraph['bbox']['x1'], text_block['bbox']['x1'])
                current_paragraph['bbox']['y1'] = max(current_paragraph['bbox']['y1'], text_block['bbox']['y1'])
                
                # æ›´æ–°ä¸­å¿ƒç‚¹
                current_paragraph['center']['x'] = (current_paragraph['center']['x'] + text_block['center']['x']) / 2
                current_paragraph['center']['y'] = (current_paragraph['center']['y'] + text_block['center']['y']) / 2
                
                # åˆå¹¶æ–‡æœ¬
                current_paragraph['texts'].append(text_block['text'])
                
                # æ›´æ–°ç½®ä¿¡åº¦ï¼ˆå–å¹³å‡å€¼ï¼‰
                current_paragraph['confidence'] = (current_paragraph['confidence'] + text_block['confidence']) / 2
                
                merge_count += 1
            else:
                # ä¿å­˜å½“å‰æ®µè½å¹¶å¼€å§‹æ–°æ®µè½
                current_paragraph['text'] = ' '.join(current_paragraph['texts'])
                paragraphs.append(current_paragraph)
                
                new_paragraph = text_block.copy()
                new_paragraph['texts'] = [new_paragraph.pop('text')]
                current_paragraph = new_paragraph
        
        # æ·»åŠ æœ€åä¸€ä¸ªæ®µè½
        current_paragraph['text'] = ' '.join(current_paragraph['texts'])
        paragraphs.append(current_paragraph)
        
        # è¿‡æ»¤å­—æ•°è¿‡å°‘çš„æ®µè½
        print(f"ğŸ“‹  åˆå¹¶å®Œæˆï¼Œåˆæ­¥å¾—åˆ°{len(paragraphs)}ä¸ªæ®µè½")
        print(f"ğŸ”  è¿‡æ»¤å­—æ•°å°‘äº{self.config['paragraph_min_words']}çš„æ®µè½...")
        filtered_paragraphs = [p for p in paragraphs if len(p['text']) >= self.config['paragraph_min_words']]
        
        # ä¸ºæ®µè½æ·»åŠ å”¯ä¸€æ ‡è¯†ç¬¦
        for i, paragraph in enumerate(filtered_paragraphs):
            paragraph['paragraph_id'] = f"para_{i+1}"
        
        print(f"âœ…  æ®µè½åˆå¹¶å®Œæˆï¼Œæœ€ç»ˆå¾—åˆ°{len(filtered_paragraphs)}ä¸ªæœ‰æ•ˆæ®µè½")
        print(f"ğŸ”  å…±åˆå¹¶äº†{merge_count}æ¬¡æ–‡æœ¬å—")
        
        # æ˜¾ç¤ºå‰å‡ ä¸ªæ®µè½ä½œä¸ºé¢„è§ˆ
        if filtered_paragraphs:
            preview_count = min(2, len(filtered_paragraphs))
            print(f"ğŸ“„  å‰{preview_count}ä¸ªæ®µè½é¢„è§ˆ:")
            for i in range(preview_count):
                para = filtered_paragraphs[i]
                preview_text = para['text'][:50] + '...' if len(para['text']) > 50 else para['text']
                print(f"   [{para['paragraph_id']}] {preview_text} (å­—æ•°: {len(para['text'])}, ç½®ä¿¡åº¦: {para['confidence']:.4f})")
        
        return filtered_paragraphs
    
    def identify_layout_elements(self, paragraphs: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """è¯†åˆ«ç‰ˆé¢å…ƒç´ ç±»å‹ï¼ˆå¦‚æ ‡é¢˜ã€æ­£æ–‡ç­‰ï¼‰
        
        Args:
            paragraphs: æ®µè½åˆ—è¡¨
            
        Returns:
            æ·»åŠ äº†å…ƒç´ ç±»å‹çš„æ®µè½åˆ—è¡¨
        """
        print("ğŸ”  å¼€å§‹è¯†åˆ«ç‰ˆé¢å…ƒç´ ç±»å‹...")
        
        # ç»Ÿè®¡å„ç±»å…ƒç´ çš„æ•°é‡
        element_counts = {'title': 0, 'text': 0}
        
        # è¿™æ˜¯ä¸€ä¸ªç®€åŒ–çš„å®ç°ï¼ŒåŸºäºæ–‡æœ¬ç‰¹å¾åˆæ­¥åˆ¤æ–­å…ƒç´ ç±»å‹
        for i, paragraph in enumerate(paragraphs):
            # æ ¹æ®æ–‡æœ¬ç‰¹å¾åˆæ­¥åˆ¤æ–­å…ƒç´ ç±»å‹
            text_length = len(paragraph['text'])
            text_lines = paragraph['text'].count('\n') + 1
            
            # ç®€å•è§„åˆ™ï¼šæ–‡æœ¬è¡Œå°‘ä½†æ¯è¡Œæ–‡å­—å°‘ï¼Œå¯èƒ½æ˜¯æ ‡é¢˜
            if text_lines <= 3 and text_length < 100 and paragraph['confidence'] > 0.8:
                element_type = 'title'
            # æ–‡æœ¬è¡Œæ•°å¤šï¼Œå¯èƒ½æ˜¯æ­£æ–‡
            elif text_lines > 2 and text_length > 50:
                element_type = 'text'
            # å…¶ä»–æƒ…å†µä½œä¸ºæ™®é€šæ–‡æœ¬
            else:
                element_type = 'text'
            
            # æ›´æ–°è®¡æ•°
            element_counts[element_type] += 1
            
            # ä¸ºå…ƒç´ æ·»åŠ å”¯ä¸€æ ‡è¯†ç¬¦
            paragraph['element_id'] = f"{element_type}_{i+1}"
            paragraph['element_type'] = element_type
        
        print(f"âœ…  ç‰ˆé¢å…ƒç´ è¯†åˆ«å®Œæˆï¼Œå…±è¯†åˆ«{len(paragraphs)}ä¸ªå…ƒç´ ")
        print(f"ğŸ“Š  å…ƒç´ ç±»å‹ç»Ÿè®¡: æ ‡é¢˜ {element_counts['title']}ä¸ª, æ­£æ–‡ {element_counts['text']}ä¸ª")
        
        return paragraphs
    
    def align_layout(self, paragraphs: List[Dict[str, Any]]) -> Dict[str, Any]:
        """æ‰§è¡Œç‰ˆé¢å¯¹é½ï¼Œç”Ÿæˆç»“æ„åŒ–çš„ç‰ˆé¢ä¿¡æ¯
        
        Args:
            paragraphs: æ®µè½åˆ—è¡¨
            
        Returns:
            ç»“æ„åŒ–çš„ç‰ˆé¢ä¿¡æ¯å­—å…¸
        """
        if not paragraphs:
            print("âŒ  æ²¡æœ‰æ®µè½å¯è¿›è¡Œç‰ˆé¢å¯¹é½")
            return {}
            
        # è¯†åˆ«ç‰ˆé¢å…ƒç´ ç±»å‹
        print("ğŸ“  å¼€å§‹æ‰§è¡Œç‰ˆé¢å¯¹é½...")
        layout_elements = self.identify_layout_elements(paragraphs)
        
        # è®¡ç®—æ•´ä½“è¾¹ç•Œæ¡†
        if layout_elements:
            x0 = min(e['bbox']['x0'] for e in layout_elements)
            y0 = min(e['bbox']['y0'] for e in layout_elements)
            x1 = max(e['bbox']['x1'] for e in layout_elements)
            y1 = max(e['bbox']['y1'] for e in layout_elements)
        else:
            x0, y0, x1, y1 = 0, 0, 0, 0
        
        print(f"ğŸ“  è®¡ç®—æ•´ä½“ç‰ˆé¢è¾¹ç•Œ: x0={x0}, y0={y0}, x1={x1}, y1={y1}")
        
        # ç”Ÿæˆç‰ˆé¢ä¿¡æ¯
        layout_info = {
            'layout_bbox': {'x0': x0, 'y0': y0, 'x1': x1, 'y1': y1},
            'element_count': len(layout_elements),
            'elements': layout_elements,
            'element_types_count': {
                'title': sum(1 for e in layout_elements if e['element_type'] == 'title'),
                'text': sum(1 for e in layout_elements if e['element_type'] == 'text')
            }
        }
        
        print(f"âœ…  ç‰ˆé¢å¯¹é½å®Œæˆ")
        
        return layout_info

class OCRPipeline:
    """OCRå®Œæ•´å¤„ç†æµæ°´çº¿"""
    
    def __init__(self, config: Dict[str, Any] = None):
        """åˆå§‹åŒ–OCRå¤„ç†æµæ°´çº¿"""
        self.default_config = {
            'output_dir': './ocr_output',
            'image_preprocess': {},
            'ocr_recognize': {},
            'layout_align': {}
        }
        self.config = self.default_config.copy()
        if config:
            self.config.update(config)
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        os.makedirs(self.config['output_dir'], exist_ok=True)
        
        # åˆå§‹åŒ–å„ä¸ªç»„ä»¶
        self.preprocessor = ImagePreprocessor(self.config['image_preprocess'])
        
        # æ£€æŸ¥paddleocræ˜¯å¦å¯ç”¨
        if paddleocr is None:
            logger.warning("PaddleOCRåº“ä¸å¯ç”¨ï¼ŒOCRåŠŸèƒ½å°†æ— æ³•ä½¿ç”¨")
            self.ocr_processor = None
        else:
            self.ocr_processor = OCRProcessor(self.config['ocr_recognize'])
        
        self.layout_aligner = LayoutAligner(self.config['layout_align'])
        
        logger.info(f"OCRå¤„ç†æµæ°´çº¿åˆå§‹åŒ–å®Œæˆï¼Œé…ç½®: {self.config}")
    
    def process_file(self, file_path: str) -> Dict[str, Any]:
        """å¤„ç†å•ä¸ªæ–‡ä»¶çš„å®Œæ•´æµç¨‹"""
        logger.info(f"å¼€å§‹å¤„ç†æ–‡ä»¶: {file_path}")
        
        # 1. å›¾åƒé¢„å¤„ç†
        logger.info("æ‰§è¡Œå›¾åƒé¢„å¤„ç†...")
        print("ğŸ”§  å¼€å§‹å›¾åƒé¢„å¤„ç†...")
        preprocessed_image, rotation_angle = self.preprocessor.preprocess(file_path)
        if preprocessed_image is None:
            logger.error("å›¾åƒé¢„å¤„ç†å¤±è´¥ï¼Œæ— æ³•ç»§ç»­å¤„ç†")
            print("âŒ  å›¾åƒé¢„å¤„ç†å¤±è´¥ï¼Œæ— æ³•ç»§ç»­å¤„ç†")
            return {}
        
        logger.info(f"é¢„å¤„ç†å®Œæˆï¼Œæ ¡æ­£å€¾æ–œè§’åº¦: {rotation_angle:.2f}åº¦")
        print(f"âœ…  å›¾åƒé¢„å¤„ç†å®Œæˆï¼Œæ ¡æ­£å€¾æ–œè§’åº¦: {rotation_angle:.2f}åº¦")
        print(f"ğŸ”  é¢„å¤„ç†åå›¾åƒå°ºå¯¸: {preprocessed_image.shape[1]}x{preprocessed_image.shape[0]}")
        
        # 2. æ£€æŸ¥OCRå¤„ç†å™¨æ˜¯å¦å¯ç”¨
        if self.ocr_processor is None or self.ocr_processor.ocr is None:
            logger.error("OCRå¤„ç†å™¨ä¸å¯ç”¨ï¼Œæ— æ³•è¿›è¡Œæ–‡æœ¬è¯†åˆ«")
            print("âš ï¸  OCRåŠŸèƒ½æ— æ³•ä½¿ç”¨ï¼Œè¿™å¯èƒ½æ˜¯ç”±äºä»¥ä¸‹åŸå› ï¼š")
            print("1. PaddleOCRåº“æœªæ­£ç¡®å®‰è£…")
            print("2. Pythonç‰ˆæœ¬(3.13)ä¸PyTorchä¸å…¼å®¹")
            print("3. ç¼ºå°‘å¿…è¦çš„ç³»ç»Ÿä¾èµ–")
            print("å»ºè®®ï¼š")
            print("- ä½¿ç”¨Python 3.8-3.11ç‰ˆæœ¬é‡æ–°è¿è¡Œ")
            print("- æ‰‹åŠ¨å®‰è£…PaddleOCRåŠå…¶ä¾èµ–")
            print("- æ£€æŸ¥ç³»ç»Ÿæ˜¯å¦å®‰è£…äº†æ‰€æœ‰å¿…è¦çš„CUDAç»„ä»¶ï¼ˆå¦‚ä½¿ç”¨GPUï¼‰")
            return {}
        
        # 3. OCRè¯†åˆ«
        logger.info("æ‰§è¡ŒOCRè¯†åˆ«...")
        print("ğŸ”  å¼€å§‹OCRæ–‡æœ¬è¯†åˆ«...")
        recognized_texts = self.ocr_processor.recognize(preprocessed_image)
        if not recognized_texts:
            logger.warning("æœªè¯†åˆ«åˆ°ä»»ä½•æ–‡æœ¬")
            print("âŒ  æœªè¯†åˆ«åˆ°ä»»ä½•æ–‡æœ¬")
            return {}
        
        logger.info(f"OCRè¯†åˆ«å®Œæˆï¼Œè¯†åˆ«åˆ°{len(recognized_texts)}ä¸ªæ–‡æœ¬å—")
        print(f"âœ…  OCRè¯†åˆ«å®Œæˆï¼Œè¯†åˆ«åˆ°{len(recognized_texts)}ä¸ªæ–‡æœ¬å—")
        
        # 4. è¯„ä¼°è¯†åˆ«å‡†ç¡®ç‡
        print("ğŸ“Š  è¯„ä¼°OCRè¯†åˆ«å‡†ç¡®ç‡...")
        accuracy_metrics = self.ocr_processor.evaluate_accuracy(recognized_texts)
        logger.info(f"OCRè¯†åˆ«å‡†ç¡®ç‡è¯„ä¼°: å¹³å‡ç½®ä¿¡åº¦={accuracy_metrics['average_confidence']:.4f}, \
                    é«˜ç½®ä¿¡åº¦æ¯”ä¾‹={accuracy_metrics['high_confidence_rate']:.4f}, \
                    ä½ç½®ä¿¡åº¦æ•°é‡={accuracy_metrics['low_confidence_count']}")
        print(f"âœ…  å‡†ç¡®ç‡è¯„ä¼°å®Œæˆï¼Œå¹³å‡ç½®ä¿¡åº¦: {accuracy_metrics['average_confidence']:.4f}")
        
        # 5. æ®µè½åˆå¹¶
        logger.info("æ‰§è¡Œæ®µè½åˆå¹¶...")
        print("ğŸ“  æ‰§è¡Œæ®µè½åˆå¹¶...")
        paragraphs = self.layout_aligner.merge_paragraphs(recognized_texts)
        logger.info(f"æ®µè½åˆå¹¶å®Œæˆï¼Œåˆå¹¶ä¸º{len(paragraphs)}ä¸ªæ®µè½")
        print(f"âœ…  æ®µè½åˆå¹¶å®Œæˆï¼Œåˆå¹¶ä¸º{len(paragraphs)}ä¸ªæ®µè½")
        
        # 6. ç‰ˆé¢å¯¹é½
        logger.info("æ‰§è¡Œç‰ˆé¢å¯¹é½...")
        print("ğŸ“  æ‰§è¡Œç‰ˆé¢å¯¹é½...")
        layout_info = self.layout_aligner.align_layout(paragraphs)
        print(f"âœ…  ç‰ˆé¢å¯¹é½å®Œæˆ")
        
        # 7. ç”Ÿæˆå®Œæ•´ç»“æœ
        print("ğŸ“‹  ç”Ÿæˆå®Œæ•´å¤„ç†ç»“æœ...")
        try:
            import pandas as pd
            timestamp = pd.Timestamp.now().isoformat()
        except ImportError:
            # å¦‚æœæ²¡æœ‰pandasï¼Œä½¿ç”¨åŸºæœ¬çš„æ—¶é—´æˆ³
            import datetime
            timestamp = datetime.datetime.now().isoformat()
        
        result = {
            'file_path': file_path,
            'preprocessing_info': {
                'rotation_angle': rotation_angle
            },
            'ocr_metrics': accuracy_metrics,
            'layout_info': layout_info,
            'recognized_texts': recognized_texts,
            'timestamp': timestamp
        }
        
        print("âœ…  å®Œæ•´ç»“æœç”ŸæˆæˆåŠŸ")
        return result
    
    def save_results(self, result: Dict[str, Any], output_dir: str = None) -> Dict[str, str]:
        """ä¿å­˜å¤„ç†ç»“æœåˆ°æ–‡ä»¶"""
        if not result:
            logger.warning("æ²¡æœ‰ç»“æœå¯ä»¥ä¿å­˜")
            return {}
        
        # ä½¿ç”¨æŒ‡å®šçš„è¾“å‡ºç›®å½•æˆ–é»˜è®¤ç›®å½•
        save_dir = output_dir or self.config['output_dir']
        os.makedirs(save_dir, exist_ok=True)
        
        # è·å–æ–‡ä»¶åï¼ˆä¸åŒ…å«æ‰©å±•åï¼‰
        file_name = os.path.splitext(os.path.basename(result['file_path']))[0]
        
        # ä¿å­˜å®Œæ•´ç»“æœä¸ºJSON
        json_path = os.path.join(save_dir, f"{file_name}_ocr_result.json")
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(result, f, ensure_ascii=False, indent=2)
        
        # ä¿å­˜çº¯æ–‡æœ¬ç»“æœ
        text_path = os.path.join(save_dir, f"{file_name}_ocr_text.txt")
        with open(text_path, 'w', encoding='utf-8') as f:
            if 'layout_info' in result and 'elements' in result['layout_info']:
                for element in result['layout_info']['elements']:
                    if 'text' in element:
                        f.write(element['text'] + '\n\n')
        
        # ä¿å­˜ç‰ˆé¢å…ƒç´ ä¿¡æ¯
        layout_path = os.path.join(save_dir, f"{file_name}_layout_info.json")
        if 'layout_info' in result:
            with open(layout_path, 'w', encoding='utf-8') as f:
                json.dump(result['layout_info'], f, ensure_ascii=False, indent=2)
        
        return {
            'json_result': json_path,
            'text_result': text_path,
            'layout_info': layout_path
        }

def main():
    """ä¸»å‡½æ•° - OCRå¤„ç†æµæ°´çº¿å…¥å£"""
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(description='OCRä¸ç‰ˆé¢å¯¹é½å·¥å…·')
    parser.add_argument('--input_file', type=str, 
                        default='data\ç™¾å¹´IBMçš„24ä¸ªç¬é—´ï¼šä»åˆ¶è¡¨æœºåˆ°è¶…çº§è®¡ç®—æœº.pdf',
                        help='è¾“å…¥æ–‡ä»¶è·¯å¾„ï¼Œæ”¯æŒPDFå’Œå›¾åƒæ–‡ä»¶')
    parser.add_argument('--output_dir', type=str, 
                        default='./ocr_output',
                        help='è¾“å‡ºç›®å½•')
    # æ³¨æ„ï¼šæ–°ç‰ˆPaddleOCRå·²è‡ªåŠ¨å¤„ç†GPUæ”¯æŒï¼Œæ— éœ€æ˜¾å¼è®¾ç½®
    args = parser.parse_args()
    
    # æ˜¾ç¤ºå½“å‰ä»»åŠ¡ä¿¡æ¯
    print("=" * 60)
    print(f"ğŸ“  å¾…å¤„ç†æ–‡ä»¶: {args.input_file}")
    print(f"ğŸ“‚  è¾“å‡ºç›®å½•: {args.output_dir}")
    print(f"âš™ï¸  PaddleOCRç‰ˆæœ¬: æ–°ç‰ˆ(è‡ªåŠ¨GPUæ”¯æŒ)")
    print("=" * 60)
    
    # åˆå§‹åŒ–OCRå¤„ç†æµæ°´çº¿
    config = {
        'output_dir': args.output_dir
    }
    print("ğŸ”„  åˆå§‹åŒ–OCRå¤„ç†æµæ°´çº¿...")
    pipeline = OCRPipeline(config)
    print("âœ…  æµæ°´çº¿åˆå§‹åŒ–å®Œæˆ")
    
    # å¤„ç†æ–‡ä»¶
    print("\n===== å¼€å§‹OCRå¤„ç†ä»»åŠ¡ =====")
    print("ğŸ“‹  å¤„ç†æµç¨‹: å›¾åƒé¢„å¤„ç† â†’ æ–‡æœ¬è¯†åˆ« â†’ å‡†ç¡®ç‡è¯„ä¼° â†’ æ®µè½åˆå¹¶ â†’ ç‰ˆé¢å¯¹é½ â†’ ç»“æœä¿å­˜")
    result = pipeline.process_file(args.input_file)
    
    if not result:
        print("âš ï¸  å¤„ç†å¤±è´¥ï¼Œæœªç”Ÿæˆä»»ä½•ç»“æœ")
        return
    
    # ä¿å­˜ç»“æœ
    print("ğŸ’¾  æ­£åœ¨ä¿å­˜å¤„ç†ç»“æœ...")
    saved_paths = pipeline.save_results(result)
    
    # æ˜¾ç¤ºè¯¦ç»†ç»“æœä¿¡æ¯
    print(f"\nğŸ‰  OCRå¤„ç†ä»»åŠ¡å·²å®Œæˆï¼")
    print(f"ğŸ“Š  å¤„ç†ç»Ÿè®¡ä¿¡æ¯:")
    print(f"  â”œâ”€â”€ è¯†åˆ«æ–‡æœ¬å—æ•°é‡: {len(result.get('recognized_texts', []))}")
    if 'layout_info' in result:
        print(f"  â”œâ”€â”€ åˆå¹¶æ®µè½æ•°é‡: {len(result['layout_info'].get('elements', []))}")
        print(f"  â”‚   â”œâ”€â”€ æ ‡é¢˜æ•°é‡: {result['layout_info'].get('element_types_count', {}).get('title', 0)}")
        print(f"  â”‚   â””â”€â”€ æ­£æ–‡æ•°é‡: {result['layout_info'].get('element_types_count', {}).get('text', 0)}")
    if 'ocr_metrics' in result:
        print(f"  â””â”€â”€ å¹³å‡ç½®ä¿¡åº¦: {result['ocr_metrics']['average_confidence']:.4f}")
    print(f"\nğŸ“  è¾“å‡ºæ–‡ä»¶:")
    for name, path in saved_paths.items():
        print(f"  â””â”€â”€ {name}: {path}")
    print("=" * 60)
    print("âœ…  ä»»åŠ¡å®Œæˆ")

if __name__ == '__main__':
    main()