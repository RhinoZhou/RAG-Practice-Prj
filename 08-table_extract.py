#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
è¡¨æ ¼æŠ½å–å·¥å…·
åŠŸèƒ½ï¼šä»PDFæ–‡ä»¶ä¸­æŠ½å–è¡¨æ ¼ï¼Œå¹¶å¯¼å‡ºä¸ºJSONå’ŒMarkdownæ ¼å¼
è¾“å…¥ï¼šPDFé¡µé¢å›¾/æ–‡æœ¬ï¼ˆç‰¹åˆ«æ˜¯dataå­ç›®å½•ä¸‹çš„å°±ä¸šæŒ‡å¯¼è€ƒè¯•è¡¨æ ¼.pdfï¼‰
å¤„ç†ï¼šä½¿ç”¨pdfplumberæŠ½å–è¡¨æ ¼ï¼Œè¿›è¡Œåˆ—å¯¹é½ç‡æ ¡éªŒã€åˆå¹¶å•å…ƒæ ¼æ‹†è§£
è¾“å‡ºï¼šè¡¨æ ¼JSONï¼ˆæ ‡å‡†schemaï¼‰+ Markdownï¼ˆå¯ç´¢å¼•ï¼‰

ä½¿ç”¨è¯´æ˜ï¼š
1. å®‰è£…ä¾èµ–ï¼špip install pdfplumber pandas
2. å¦‚éœ€Excelå¯¼å‡ºåŠŸèƒ½ï¼špip install openpyxl
3. è¿è¡Œç¤ºä¾‹ï¼špython 08-table_extract.py --pdf_path data/å°±ä¸šæŒ‡å¯¼è€ƒè¯•è¡¨æ ¼.pdf

æ³¨ï¼šç¨‹åºä¼šè‡ªåŠ¨åœ¨è¾“å‡ºç›®å½•åˆ›å»ºè¡¨æ ¼æ–‡ä»¶ï¼Œå¹¶åœ¨ç»ˆç«¯æ˜¾ç¤ºå¤„ç†è¿›åº¦å’Œç»“æœã€‚
"""

import os
import json
import logging
import argparse
import pandas as pd
import pdfplumber
from typing import List, Dict, Any, Optional, Tuple

# é…ç½®æ—¥å¿— - åŒæ—¶è¾“å‡ºåˆ°æ–‡ä»¶å’Œæ§åˆ¶å°
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler("table_extract_log.txt"),  # æ—¥å¿—æ–‡ä»¶
        logging.StreamHandler()  # æ§åˆ¶å°è¾“å‡º
    ]
)
logger = logging.getLogger('TableExtractor')  # åˆ›å»ºæ—¥å¿—è®°å½•å™¨

class TableExtractor:
    """è¡¨æ ¼æŠ½å–å™¨ï¼Œè´Ÿè´£ä»PDFä¸­æŠ½å–è¡¨æ ¼å¹¶è¿›è¡Œå¤„ç†"""
    
    def __init__(self, config: Dict[str, Any] = None):
        """
        åˆå§‹åŒ–è¡¨æ ¼æŠ½å–å™¨
        
        Args:
            config: é…ç½®å‚æ•°
        """
        # é»˜è®¤é…ç½®
        self.default_config = {
            'output_dir': './table_output',  # è¾“å‡ºç›®å½•
            'min_row_count': 2,              # æœ€å°è¡Œæ•°
            'min_col_count': 2,              # æœ€å°åˆ—æ•°
            'vertical_alignment_threshold': 0.4,  # åˆ—å¯¹é½ç‡é˜ˆå€¼ï¼ˆé™ä½è¦æ±‚ä»¥ä¾¿æ•è·æ›´å¤šè¡¨æ ¼ï¼‰
            'edge_tolerance': 1.0,           # è¾¹ç¼˜å®¹å¿åº¦
            'snap_tolerance': 3.0,           # æ•æ‰å®¹å¿åº¦
            'extract_kwargs': {
                'vertical_strategy': 'lines',  # å‚ç›´çº¿æ£€æµ‹ç­–ç•¥
                'horizontal_strategy': 'lines',  # æ°´å¹³çº¿æ£€æµ‹ç­–ç•¥
                'snap_x_tolerance': 3.0,       # Xè½´æ•æ‰å®¹å¿åº¦
                'snap_y_tolerance': 3.0,       # Yè½´æ•æ‰å®¹å¿åº¦
            }
        }
        
        # åˆå¹¶ç”¨æˆ·é…ç½®
        self.config = self.default_config.copy()
        if config:
            self.config.update(config)
            # åˆå¹¶extract_kwargs
            if 'extract_kwargs' in config:
                self.config['extract_kwargs'].update(config['extract_kwargs'])
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        os.makedirs(self.config['output_dir'], exist_ok=True)
        
        logger.info(f"è¡¨æ ¼æŠ½å–å™¨åˆå§‹åŒ–å®Œæˆï¼Œé…ç½®: {self.config}")
    
    def extract_tables_from_pdf(self, pdf_path: str) -> List[Dict[str, Any]]:
        """
        ä»PDFæ–‡ä»¶ä¸­æŠ½å–æ‰€æœ‰è¡¨æ ¼
        
        Args:
            pdf_path: PDFæ–‡ä»¶è·¯å¾„
        
        Returns:
            åŒ…å«æ‰€æœ‰æŠ½å–è¡¨æ ¼ä¿¡æ¯çš„åˆ—è¡¨
        """
        if not os.path.exists(pdf_path):
            logger.error(f"æ–‡ä»¶ä¸å­˜åœ¨: {pdf_path}")
            return []
        
        tables_info = []
        try:
            with pdfplumber.open(pdf_path) as pdf:
                # è·å–PDFæ–‡ä»¶åï¼Œä¸åŒ…å«æ‰©å±•å
                pdf_name = os.path.splitext(os.path.basename(pdf_path))[0]
                
                for page_num, page in enumerate(pdf.pages, 1):
                    logger.info(f"æ­£åœ¨å¤„ç†ç¬¬{page_num}é¡µ")
                    
                    try:
                        # å°è¯•ç›´æ¥æå–è¡¨æ ¼ï¼ˆä¸ä½¿ç”¨é¢å¤–å‚æ•°ï¼‰
                        tables = page.extract_tables()
                    except Exception as e:
                        logger.error(f"æå–è¡¨æ ¼æ—¶å‡ºé”™: {e}")
                        tables = []
                    
                    if not tables:
                        logger.info(f"ç¬¬{page_num}é¡µæœªå‘ç°è¡¨æ ¼")
                        continue
                    
                    logger.info(f"ç¬¬{page_num}é¡µå‘ç°{len(tables)}ä¸ªè¡¨æ ¼")
                    
                    # è·å–é¡µé¢å°ºå¯¸ï¼Œç”¨äºåæ ‡è®¡ç®—
                    page_width = page.width
                    page_height = page.height
                    
                    # å¤„ç†æ¯ä¸ªè¡¨æ ¼
                    for table_idx, table in enumerate(tables):
                        # è·³è¿‡ç©ºè¡¨æ ¼æˆ–è¡Œæ•°/åˆ—æ•°è¿‡å°‘çš„è¡¨æ ¼
                        if not table or len(table) < self.config['min_row_count']:
                            logger.warning(f"è·³è¿‡ç¬¬{page_num}é¡µç¬¬{table_idx+1}ä¸ªè¡¨æ ¼ï¼ˆè¡Œæ•°ä¸è¶³ï¼‰")
                            continue
                        
                        # è·å–è¡¨æ ¼çš„è¾¹ç•Œæ¡†
                        table_bbox = self._get_table_bbox(page, table_idx)
                        
                        # æ ¡éªŒåˆ—å¯¹é½ç‡
                        alignment_score = self._check_column_alignment(table)
                        
                        # è¿‡æ»¤å¯¹é½ç‡ä½çš„è¡¨æ ¼
                        if alignment_score < self.config['vertical_alignment_threshold']:
                            logger.warning(f"è·³è¿‡ç¬¬{page_num}é¡µç¬¬{table_idx+1}ä¸ªè¡¨æ ¼ï¼ˆåˆ—å¯¹é½ç‡ä½: {alignment_score:.2f}ï¼‰")
                            continue
                        
                        # å¤„ç†åˆå¹¶å•å…ƒæ ¼
                        processed_table = self._handle_merged_cells(table)
                        
                        # ç”Ÿæˆè¡¨æ ¼ID
                        table_id = f"{pdf_name}_page{page_num}_table{table_idx+1}"
                        
                        # è½¬æ¢ä¸ºæ ‡å‡†schema
                        table_info = {
                            'table_id': table_id,
                            'pdf_path': pdf_path,
                            'page_num': page_num,
                            'table_index': table_idx + 1,
                            'bbox': table_bbox,
                            'page_dimensions': {
                                'width': page_width,
                                'height': page_height
                            },
                            'row_count': len(processed_table),
                            'col_count': len(processed_table[0]) if processed_table else 0,
                            'alignment_score': alignment_score,
                            'data': processed_table,
                            'metadata': {
                                'extraction_method': 'pdfplumber',
                                'config_used': self.config['extract_kwargs']
                            }
                        }
                        
                        tables_info.append(table_info)
                        logger.info(f"æˆåŠŸå¤„ç†ç¬¬{page_num}é¡µç¬¬{table_idx+1}ä¸ªè¡¨æ ¼")
        except Exception as e:
            logger.error(f"å¤„ç†PDFæ–‡ä»¶æ—¶å‡ºé”™: {e}")
        
        return tables_info
    
    def _get_table_bbox(self, page: Any, table_idx: int) -> Dict[str, float]:
        """
        è·å–è¡¨æ ¼çš„è¾¹ç•Œæ¡†
        
        Args:
            page: PDFé¡µé¢å¯¹è±¡
            table_idx: è¡¨æ ¼ç´¢å¼•
        
        Returns:
            åŒ…å«è¡¨æ ¼è¾¹ç•Œåæ ‡çš„å­—å…¸
        """
        try:
            # å°è¯•ä½¿ç”¨æ›´ç®€å•çš„æ–¹å¼è·å–è¡¨æ ¼è¾¹ç•Œ
            # ç›´æ¥è¿”å›é¡µé¢è¾¹ç•Œä½œä¸ºè¡¨æ ¼è¾¹ç•Œï¼ˆç®€åŒ–å®ç°ï¼‰
            return {
                'x0': 0,
                'top': 0,
                'x1': page.width,
                'bottom': page.height
            }
        except Exception as e:
            logger.warning(f"è·å–è¡¨æ ¼è¾¹ç•Œæ¡†æ—¶å‡ºé”™: {e}")
        
        # å¦‚æœå‡ºé”™ï¼Œè¿”å›é¡µé¢è¾¹ç•Œ
        return {
            'x0': 0,
            'top': 0,
            'x1': page.width,
            'bottom': page.height
        }
    
    def _check_column_alignment(self, table: List[List[str]]) -> float:
        """
        æ£€æŸ¥è¡¨æ ¼çš„åˆ—å¯¹é½ç‡
        
        Args:
            table: è¡¨æ ¼æ•°æ®
        
        Returns:
            å¯¹é½ç‡åˆ†æ•° (0-1)
        
        è¯´æ˜ï¼š
        - è®¡ç®—æ¯åˆ—çš„éç©ºå€¼æ¯”ä¾‹ï¼Œç”¨äºè¯„ä¼°è¡¨æ ¼çš„ç»“æ„å®Œæ•´æ€§
        - å€¼è¶Šé«˜è¡¨ç¤ºè¡¨æ ¼ç»“æ„è¶Šå®Œæ•´ï¼Œåˆ—å¯¹é½è¶Šå¥½
        - å½“å‰é˜ˆå€¼è®¾ç½®ä¸º0.4ï¼Œä½äºæ­¤å€¼çš„è¡¨æ ¼å°†è¢«è·³è¿‡
        "
        """
        if not table or len(table) < 2:
            return 0.0
        
        # è®¡ç®—æ¯åˆ—çš„éç©ºå€¼æ¯”ä¾‹ï¼ˆä¼˜åŒ–ç®—æ³•ï¼‰
        col_count = max(len(row) for row in table)
        valid_col_ratios = []
        
        for col_idx in range(col_count):
            non_empty_count = 0
            total_count = 0
            
            for row in table:
                if col_idx < len(row):
                    cell_content = str(row[col_idx]).strip() if row[col_idx] else ''
                    if cell_content:
                        non_empty_count += 1
                    total_count += 1
            
            # è®¡ç®—è¯¥åˆ—çš„æœ‰æ•ˆæ¯”ä¾‹
            if total_count > 0:
                valid_ratio = non_empty_count / total_count
                valid_col_ratios.append(valid_ratio)
        
        # è¿”å›å¹³å‡æœ‰æ•ˆæ¯”ä¾‹
        return sum(valid_col_ratios) / len(valid_col_ratios) if valid_col_ratios else 0.0
    
    def _handle_merged_cells(self, table: List[List[str]]) -> List[List[str]]:
        """
        å¤„ç†åˆå¹¶å•å…ƒæ ¼ï¼Œå°½å¯èƒ½è¿˜åŸåŸå§‹è¡¨æ ¼ç»“æ„
        
        Args:
            table: åŸå§‹è¡¨æ ¼æ•°æ®
        
        Returns:
            å¤„ç†åçš„è¡¨æ ¼æ•°æ®
        
        è¯´æ˜ï¼š
        - é¦–å…ˆç»Ÿä¸€æ¯è¡Œçš„åˆ—æ•°ï¼Œç¡®ä¿è¡¨æ ¼ç»“æ„ä¸€è‡´
        - ç„¶åæ£€æµ‹å¹¶æ ‡è®°å¯èƒ½çš„åˆå¹¶å•å…ƒæ ¼ï¼Œé€šè¿‡åœ¨å€¼åæ·»åŠ "(merged)"æ ‡è¯†
        - è¿™æ˜¯ä¸€ä¸ªåŸºäºå†…å®¹çš„å¯å‘å¼æ–¹æ³•ï¼Œå¯¹äºå¤æ‚è¡¨æ ¼å¯èƒ½éœ€è¦æ›´é«˜çº§çš„æ£€æµ‹ç®—æ³•
        """
        if not table:
            return []
        
        # ç»Ÿä¸€æ¯è¡Œçš„åˆ—æ•°
        max_cols = max(len(row) for row in table)
        processed_table = []
        
        for row in table:
            # è¡¥å……ç©ºå­—ç¬¦ä¸²ä½¿æ¯è¡Œåˆ—æ•°ä¸€è‡´
            processed_row = row + [''] * (max_cols - len(row))
            processed_table.append(processed_row)
        
        # ç®€å•çš„åˆå¹¶å•å…ƒæ ¼æ£€æµ‹ï¼šæ£€æŸ¥æ˜¯å¦æœ‰ç›¸é‚»è¡Œçš„ç›¸åŒå†…å®¹
        # è¿™æ˜¯ä¸€ä¸ªç®€åŒ–å®ç°ï¼Œæ›´å¤æ‚çš„åˆå¹¶å•å…ƒæ ¼æ£€æµ‹éœ€è¦åˆ†æPDFçš„åº•å±‚ç»“æ„
        for i in range(len(processed_table) - 1):
            for j in range(len(processed_table[i])):
                current_cell = processed_table[i][j]
                next_cell = processed_table[i+1][j]
                
                # å¦‚æœå½“å‰å•å…ƒæ ¼ä¸ä¸ºç©ºï¼Œè€Œä¸‹ä¸€è¡ŒåŒä¸€åˆ—çš„å•å…ƒæ ¼ä¸ºç©ºï¼Œå¯èƒ½æ˜¯çºµå‘åˆå¹¶
                if current_cell and not next_cell:
                    processed_table[i+1][j] = f"{current_cell} (merged)"
        
        return processed_table
    
    def export_tables_to_json(self, tables_info: List[Dict[str, Any]], output_path: str) -> bool:
        """
        å°†è¡¨æ ¼æ•°æ®å¯¼å‡ºä¸ºJSONæ ¼å¼
        
        Args:
            tables_info: è¡¨æ ¼ä¿¡æ¯åˆ—è¡¨
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        
        Returns:
            æ˜¯å¦å¯¼å‡ºæˆåŠŸ
        """
        try:
            # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
            os.makedirs(os.path.dirname(os.path.abspath(output_path)), exist_ok=True)
            
            # å†™å…¥JSONæ–‡ä»¶
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(tables_info, f, ensure_ascii=False, indent=2)
            
            logger.info(f"æˆåŠŸå¯¼å‡º{len(tables_info)}ä¸ªè¡¨æ ¼åˆ°JSONæ–‡ä»¶: {output_path}")
            return True
        except Exception as e:
            logger.error(f"å¯¼å‡ºJSONæ–‡ä»¶æ—¶å‡ºé”™: {e}")
            return False
    
    def export_tables_to_markdown(self, tables_info: List[Dict[str, Any]], output_path: str) -> bool:
        """
        å°†è¡¨æ ¼æ•°æ®å¯¼å‡ºä¸ºMarkdownæ ¼å¼
        
        Args:
            tables_info: è¡¨æ ¼ä¿¡æ¯åˆ—è¡¨
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        
        Returns:
            æ˜¯å¦å¯¼å‡ºæˆåŠŸ
        """
        try:
            # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
            os.makedirs(os.path.dirname(os.path.abspath(output_path)), exist_ok=True)
            
            with open(output_path, 'w', encoding='utf-8') as f:
                for table_info in tables_info:
                    # å†™å…¥è¡¨æ ¼å…ƒä¿¡æ¯
                    f.write(f"# è¡¨æ ¼ID: {table_info['table_id']}\n")
                    f.write(f"- æ¥æºæ–‡ä»¶: {os.path.basename(table_info['pdf_path'])}\n")
                    f.write(f"- é¡µç : {table_info['page_num']}\n")
                    f.write(f"- è¡¨æ ¼ç´¢å¼•: {table_info['table_index']}\n")
                    f.write(f"- åæ ‡: x0={table_info['bbox']['x0']:.2f}, top={table_info['bbox']['top']:.2f}, ")
                    f.write(f"x1={table_info['bbox']['x1']:.2f}, bottom={table_info['bbox']['bottom']:.2f}\n")
                    f.write(f"- è¡Œåˆ—æ•°: {table_info['row_count']}è¡Œ Ã— {table_info['col_count']}åˆ—\n")
                    f.write(f"- åˆ—å¯¹é½ç‡: {table_info['alignment_score']:.2f}\n\n")
                    
                    # å†™å…¥Markdownè¡¨æ ¼
                    table_data = table_info['data']
                    if not table_data:
                        f.write("è¡¨æ ¼æ•°æ®ä¸ºç©º\n\n")
                        continue
                    
                    # å†™å…¥è¡¨å¤´åˆ†éš”çº¿
                    headers = table_data[0]
                    separator = ['---'] * len(headers)
                    
                    # å†™å…¥è¡¨æ ¼å†…å®¹
                    f.write('| ' + ' | '.join(headers) + ' |\n')
                    f.write('| ' + ' | '.join(separator) + ' |\n')
                    
                    for row in table_data[1:]:
                        # ç¡®ä¿è¡Œçš„åˆ—æ•°ä¸è¡¨å¤´ä¸€è‡´
                        row_data = row + [''] * (len(headers) - len(row))
                        f.write('| ' + ' | '.join(str(cell).strip() for cell in row_data) + ' |\n')
                    
                    f.write('\n\n')
                    f.write('---\n\n')  # åˆ†éš”ç¬¦
            
            logger.info(f"æˆåŠŸå¯¼å‡º{len(tables_info)}ä¸ªè¡¨æ ¼åˆ°Markdownæ–‡ä»¶: {output_path}")
            return True
        except Exception as e:
            logger.error(f"å¯¼å‡ºMarkdownæ–‡ä»¶æ—¶å‡ºé”™: {e}")
            return False
    
    def export_tables_to_excel(self, tables_info: List[Dict[str, Any]], output_path: str) -> bool:
        """
        å°†è¡¨æ ¼æ•°æ®å¯¼å‡ºä¸ºExcelæ ¼å¼ï¼ˆé¢å¤–åŠŸèƒ½ï¼‰
        
        Args:
            tables_info: è¡¨æ ¼ä¿¡æ¯åˆ—è¡¨
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        
        Returns:
            æ˜¯å¦å¯¼å‡ºæˆåŠŸ
        """
        try:
            # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
            os.makedirs(os.path.dirname(os.path.abspath(output_path)), exist_ok=True)
            
            with pd.ExcelWriter(output_path, engine='openpyxl') as writer:
                for table_info in tables_info:
                    # ä¸ºå·¥ä½œè¡¨åç§°åˆ›å»ºä¸€ä¸ªç®€çŸ­çš„æ ‡è¯†ç¬¦
                    sheet_name = f"P{table_info['page_num']}_T{table_info['table_index']}"
                    # Excelå·¥ä½œè¡¨åç§°ä¸èƒ½è¶…è¿‡31ä¸ªå­—ç¬¦
                    if len(sheet_name) > 31:
                        sheet_name = sheet_name[:28] + '...'
                    
                    # åˆ›å»ºDataFrame
                    df = pd.DataFrame(table_info['data'])
                    
                    # å†™å…¥å·¥ä½œè¡¨
                    df.to_excel(writer, sheet_name=sheet_name, index=False, header=False)
                    
                    # æ·»åŠ è¡¨æ ¼å…ƒä¿¡æ¯åˆ°å·¥ä½œè¡¨é¡¶éƒ¨
                    worksheet = writer.sheets[sheet_name]
                    worksheet['A1'] = f"è¡¨æ ¼ID: {table_info['table_id']}"
                    worksheet['A2'] = f"æ¥æºæ–‡ä»¶: {os.path.basename(table_info['pdf_path'])}"
                    worksheet['A3'] = f"é¡µç : {table_info['page_num']}"
                    
                    # è°ƒæ•´æ•°æ®åŒºåŸŸçš„èµ·å§‹ä½ç½®
                    if not df.empty:
                        # ç§»åŠ¨æ•°æ®åˆ°ç¬¬5è¡Œå¼€å§‹
                        for row_idx, row in enumerate(df.itertuples(index=False, name=None), 5):
                            for col_idx, value in enumerate(row):
                                worksheet.cell(row=row_idx, column=col_idx+1, value=value)
            
            logger.info(f"æˆåŠŸå¯¼å‡º{len(tables_info)}ä¸ªè¡¨æ ¼åˆ°Excelæ–‡ä»¶: {output_path}")
            return True
        except Exception as e:
            logger.error(f"å¯¼å‡ºExcelæ–‡ä»¶æ—¶å‡ºé”™: {e}")
            return False


def main():
    """
    ä¸»å‡½æ•° - ç¨‹åºå…¥å£ç‚¹
    
    åŠŸèƒ½æµç¨‹ï¼š
    1. è§£æå‘½ä»¤è¡Œå‚æ•°
    2. åˆå§‹åŒ–è¡¨æ ¼æŠ½å–å™¨
    3. ä»PDFæ–‡ä»¶ä¸­æŠ½å–è¡¨æ ¼
    4. å°†è¡¨æ ¼å¯¼å‡ºä¸ºJSONã€Markdownæ ¼å¼ï¼ˆå¯é€‰å¯¼å‡ºExcelï¼‰
    """
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(description='PDFè¡¨æ ¼æŠ½å–å·¥å…·')
    parser.add_argument('--pdf_path', type=str, 
                        default='data/å°±ä¸šæŒ‡å¯¼è€ƒè¯•è¡¨æ ¼.pdf',
                        help='PDFæ–‡ä»¶è·¯å¾„ï¼Œé»˜è®¤ä¸ºdata/å°±ä¸šæŒ‡å¯¼è€ƒè¯•è¡¨æ ¼.pdf')
    parser.add_argument('--output_dir', type=str, 
                        default='./table_output',
                        help='è¾“å‡ºç›®å½•ï¼Œé»˜è®¤ä¸º./table_output')
    parser.add_argument('--skip_excel', action='store_true', 
                        help='è·³è¿‡Excelå¯¼å‡º')
    args = parser.parse_args()
    
    # åˆå§‹åŒ–è¡¨æ ¼æŠ½å–å™¨
    extractor = TableExtractor({
        'output_dir': args.output_dir
    })
    
    # æŠ½å–è¡¨æ ¼
    print("===== å¼€å§‹è¡¨æ ¼æŠ½å–ä»»åŠ¡ =====")
    logger.info(f"å¼€å§‹å¤„ç†æ–‡ä»¶: {args.pdf_path}")
    tables_info = extractor.extract_tables_from_pdf(args.pdf_path)
    
    if not tables_info:
        logger.warning("æœªæå–åˆ°ä»»ä½•è¡¨æ ¼")
        print("âš ï¸  è­¦å‘Šï¼šæœªä»PDFæ–‡ä»¶ä¸­æå–åˆ°ä»»ä½•è¡¨æ ¼ã€‚å¯èƒ½åŸå› ï¼š")
        print("  - PDFæ–‡ä»¶ä¸­å¯èƒ½æ²¡æœ‰ç»“æ„åŒ–è¡¨æ ¼")
        print("  - è¡¨æ ¼æ ¼å¼å¯èƒ½ä¸ç¬¦åˆå½“å‰æ£€æµ‹ç®—æ³•")
        print("  - å¯å°è¯•è°ƒæ•´vertical_alignment_thresholdå‚æ•°å€¼")
        return
    
    # è·å–è¾“å‡ºæ–‡ä»¶å
    pdf_name = os.path.splitext(os.path.basename(args.pdf_path))[0]
    
    # å¯¼å‡ºJSON
    json_output_path = os.path.join(args.output_dir, f"{pdf_name}_tables.json")
    json_success = extractor.export_tables_to_json(tables_info, json_output_path)
    if json_success:
        print(f"âœ…  å·²æˆåŠŸå¯¼å‡ºJSONæ ¼å¼è¡¨æ ¼ï¼š{json_output_path}")
    
    # å¯¼å‡ºMarkdown
    md_output_path = os.path.join(args.output_dir, f"{pdf_name}_tables.md")
    md_success = extractor.export_tables_to_markdown(tables_info, md_output_path)
    if md_success:
        print(f"âœ…  å·²æˆåŠŸå¯¼å‡ºMarkdownæ ¼å¼è¡¨æ ¼ï¼š{md_output_path}")
    
    # å¯¼å‡ºExcelï¼ˆå¯é€‰ï¼‰
    if not args.skip_excel:
        print("ğŸ“Š  æ­£åœ¨å°è¯•å¯¼å‡ºExcelæ ¼å¼...")
        excel_output_path = os.path.join(args.output_dir, f"{pdf_name}_tables.xlsx")
        excel_success = extractor.export_tables_to_excel(tables_info, excel_output_path)
        if not excel_success:
            print("âš ï¸  æç¤ºï¼šExcelå¯¼å‡ºéœ€è¦openpyxlåº“æ”¯æŒã€‚")
            print("  å¯é€šè¿‡ä»¥ä¸‹å‘½ä»¤å®‰è£…ï¼špip install openpyxl")
            print("  æˆ–ä½¿ç”¨--skip_excelå‚æ•°è·³è¿‡Excelå¯¼å‡º")
    
    print(f"\nğŸ‰  è¡¨æ ¼æŠ½å–ä»»åŠ¡å·²å®Œæˆï¼æˆåŠŸæå–äº†{len(tables_info)}ä¸ªè¡¨æ ¼")
    print(f"ğŸ“  æ‰€æœ‰è¾“å‡ºæ–‡ä»¶å·²ä¿å­˜è‡³ï¼š{args.output_dir}")
    print("===== ä»»åŠ¡å®Œæˆ =====")
    logger.info("è¡¨æ ¼æŠ½å–å’Œå¯¼å‡ºä»»åŠ¡å·²å®Œæˆ")


if __name__ == '__main__':
    main()